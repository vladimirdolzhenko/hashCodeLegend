2017-02-06

# preparation

* Idea
    * default (белая) тема
    * отключить show whitespaces
    * presentation mode
* MacOsX settings
    * Dock - automatically hide and show Dock
* Выключить все IM!

# Внутрь VM сквозь замочную скважину hashCode

Меня зовут Владимир и мы будем сквозь замочную скважину заглядывать внутрь VM java. Более точнее - OpenJDK и OracleJDK, как самые доступные и самые распострённые реализации java vm.

# план

* в начале немного откровенно покапитаню - вспомним теорию, а именно ассоциативные массивы.
* поговорим про правила вычислений hashcode
* и как можно используя знания о hashcode устроить DoS атаку, и как вылечить её
* и затем окунёмся в детали виртуальной машины при помощи всё того же hashcode - разрушим старый миф, будут и потроха - сборщик мусора, и аллокация, и немного баттлов
* и на последок ещё один трюк виртуальной машины и как hashcode может всё изменить

# Телефонная книга

В начале напомню тем, кто знает, или очень кратко и сжато расскажу тем, кто ещё не знает, что такое ассоциативный массив - на примере телефонной книги - у нас есть пара ключ - значение. Ключом будет выступать имя, а значением будет его номер телефона.

# Hash!

Для построения ассоцитивного массива нужна функция, ставящая в соответствии с ключом некоторое числовое значение. Эту функцию мы и будем называть hashcode.

Важный момент - поскольку число может быть любым - как очень большим - так и отрицательным, а доступная память ограничена - мы не можем заранее создать массив под максимально возможное значение - поэтому полученное число предстоит ещё отмасштабировать на длину массива.

 И вот тогда можно сказать, куда этот ключ в массиве надо записать.

В этом заключается главная мысль использования hashCode.

# javadoc
Более того - в java такая функция уже определена - причём у java.lang.Object - корневого класса всей иерархии классов в java.
Т.о. по-умолчанию всё классы в java обладают некоторой стандартной hash-функцией.

Так же обратим внимание, что hashcode возвращает int - это знаковое 32х битное целое число. Если бы мы пытались создавать массив под максимально возможное значение - то под каждый ассоциативный массив потребовалось как минимум 32 Гб.

# Записать ( Алексей, +791… )

Дабы лучше освежить и пояснить - рассмотрим поясняющий пример - запишем в телефонную книгу Алексея и его телефонный номер. Предположим, что его hashcode равен 15 - для пояснения работы это не принципиально, но о том как именно вычисляется hashcode мы обязательно вернёмся позже.

И так - вычисляем индекс в массиве и записываем значение.

# Найти Фёдора

Представим, что у нас уже несколько адресатов добавлено - если теперь нам надо найти телефон, зная имя человека - например - Фёдора - мы делаем почти ту же самую операцию - вычисляем hashcode, масштабируем, проверка, что искомый ключ равен требуемому ключу

# сложность
т.е алгоритм поиска никак не зависит от длины массива - сложность константа.

это самое главное свойство ассоцитивного массива.

# Изменение hashCode

ложка дёгтя - что случится, если hashCode Фёдора по какой-либо причине изменится - если теперь мы попробуем найти его в нашей телефонной книге - то мы просто не найдём Фёдора.

И зачем нам вообще тогда этот hashCode нужен, если могут случаться такие сюрпризы!? может лучше старым добрым перебором, но таки найти адресата.

# Контракт hashCode

надо жёстко ограничить такое поведение  - и javadoc определяет контракт для hashcode -  сколько бы раз не вызывали ли мы hashCode он должен постоянно возвращать одно и то же значение hashcode.

т.о. hashcode это не всякая функция, которая ставит в соответствии с объектом какое-то число, а функция, которая обладает рядом свойств - и неизменчивость это одно из них.

# Коллизии

но на этом неприятности не заканчиваются.

Что, если нам предстоит записать Alexander, Alex и Jan - и, предположим, что у всех такой же hashcode, как и у Алексея.

Нельзя же перезаписать в ту же самую ячейку массива новые ключи, но с одинаковым hashcode - так мы будем терять ранее записанные ключи - что далает такую структуру данных сильно ограниченной в области применимости.

Совпадение hashcode ключей - это коллизия, и её придётся как-то разрешать - ситуация не приятная, но типичная.

Надо сказать, что коллизии это самая большая проблема в хэш-структурах - используют и разные подходы для разрешия коллизий, и чтобы их не допустить - стараются найти хэш-функцию получше, но для общего случая её сложно подобрать.

# Chaining
И т.к такой идеальной функции нет - то используют то, что есть - а есть то, что либо вернул метод hashCode() - и что там пользователь напишет - может быть ужас-ужас. коллизии разрешают  - один из способов разрешить - chaining - это создать список и поместить все ключи с одинаковыми hashcode в него. способ универсальный, но далек от идеала, и как плата за это - сложность поиска становится линейной.

Это очень важный момент - коллизии способны сломать производительность, и чем больше коллизий, тем только хуже операции типа поиска, вставки и т.п

Про другие способы разрешения коллизий я не буду говорить, т.к. они имеют более строгие ограничения и не подходят для общего случая.

# hashCode = функция ( содержимое объекта )

Как же вычисляется hashCode ? как правило hash-функция это некоторая функция над содержимым объекта.

И хорошо бы знать, как он должен быть как-то вычислен - ведь не важно - получили ли мы строку по сети, или пользователь ввёл в форму данные, или как-то ещё - ключ один и тот же с точки зрения содержимого - значит и equals - а следовательно и hashcode должен быть один и тот же.

Т.е, что строки java, что экземпляры 42 - каждый из них имеет один и тот же hashcode соответственно.

# простой hashCode

Давайте начнём с простого примера - и рассмотрим точку - у которой есть два свойства - x и y.

Вообще, строго говоря - в качестве hashcode может быть всё, что угодно - хотите возвращайте константу, но тогда можно забыть об быстром доступе по ключу. Т.е. чем лучше будет hash-функция и чем меньше будет коллизий - тем будет лучше.

У Джошуа Блоха в его книге Effective Java этому посвящёна отдельная глава - Традиционно для общего случая рекомендуется использовать сумму с простыми весами, опять же в угоду минимизации коллизий - и с другой стороны мы хотим, чтобы метод был относительно простой и не требовал много ресурсов на вычисление.

Как правило, общий случай решает усреднённую задачу, для большинства случаев - однако, если у вас узко специализированная задача и вы знаете диапозон допустимых значений - то можно подобрать другие коэффециенты дабы минимизировать коллизии.

(Например, если вы работаете в квадрате 100 на 100 - то почему бы не выбрать множитель больше 100 и посмотреть распределение коллизий для известного набора данных.)

И конечно же не забывайте переопределять метод equals, который должен быть согласован с hashcode

да - и используйте только не изменяемые свойства для вычисления hashcode - лучше всего final свойства - или по крайней мере не меняйте значения

# Objects.hash
И начиная с 7ки - hashCode можно вычислить просто передав свойства в utility method - и все вычисления для средне-хорошего случая будут проведены внутри.

В общем случае это будет полиминальная функция от количества аргументов.

# Полиномиальный hashCode

И как раз одну из типичных полиминальных реализаций hashCode -  можно увидеть в строке - складываем все элементы массива с весами по степеням 31.

Но почему именно 31 ? Не 2, не 5, а именно 31 ? Есть идеи ?

# 31 : Детективная история

Есть такой вот замечательный баг - в самых первых версиях java hashcode для строки вычислялся архаичным способом.

И один из отцов Java - небезызвестный Джошуа Блох решил это исправить - в книге Kernighan и Ritchie - Язык программирования Си - был дан готовый рецепт - и без доказательно даётся полиминальная функция с числом 31 - тогда Джошуа связался с Брайном Керниганом - но тот забыл уже откуда он взял это число - просто оно работает.

Блох провёл небольшое исследование - взял слова и словоформы из словаря Merriam-Webster, все строки в солярисе в /bin/*, /usr/bin/* и т.д - и на последок он запустил веб-паука, который за несколько часов собрал ему около 30 тыс урлов - сейчас это выглядит более, чем забавно - но 20 лет назад таков был интернет.

И вот он собрал все эти строки и проанализировал уровень коллизий - та, реализация, которая была на тот момент давала очень высокий уровень коллизий, а уровень коллизий при коэффециентах 31, 33 и 37 оказался примерно одинаковый. + 31 достаточно близко к 32, так, что многие компиляторы могут представить умножение 31 как сдвиг и вычитание.

Словом - в результате было выбрано число 31 - как и у Kernighan и Ritchie. В чём-то это Ответ на главный вопрос жизни, вселенной и всего такого в java.

# Но ведь можно подобрать…

Но ведь далеко не все строки осмысленные слова - можно же подобрать такие значения, зная он как вычисляется - можно найти такие строки, которые будут иметь один и тот же hash code.

например - строки Аа и ББ - один самых известных примеров

Возьмём два рядом стоящих символа в строке -
если уменьшаем левый на 1, то правый - надо увеличить на 31.
Или наоборот, если левый увеличиваем на 1 - то правый уменьшаем на 31.
Подобный приём можно применить для двух символов, между которыми находится ещё один, и т.д. Проще всего искать строки такой же длины - отталкиваясь от уже существующей строки - хотя конечно можно искать и варианты с бОльшей длиной строки - играя на переполнении целого числа.

Для примера я взял строку "username" и направленным поиском - меняя соседние символы - нашёл почти полмиллиона вариантов.

Думаю, что понятно, что чем длинее строка, тем больше можно найти или подобрать вариантов коллизий, в то время, когда если строка состоит только из одного символа - например q - то там труднее развернутся - только искать строки бОльшей длины.

и давайте измеряем влияние коллизий.

# JMH

и здесь и далее я буду использовать jmh для измерения производительности

поднимите руки, если в зале кто-то не знает или не слышал о jmh ? а теперь, кто что-то хотя бы слышал о нём. и кто его и знает, и использует или иногда использует.

Если кто не знает - буквально кратко - что это и зачем - написать бенчмарк не составляет особого труда, но написать корректный бенчмарк, который будет действительно правильно замерять и измерять именно то, что хочется - это значительно сложнее.

и jmh это фреймфорк по написанию правильных nano/micro/milli performance benchmarks для java. он составляет часть openjdk toolset и так же люди из openjdk его поддерживают и развивают.

# Java Microbenchmark Harness (1)

Примерно вот так или подобно выглядит benchmark на jmh - у нас есть само тело бенчмарка - как раз мы измеряем как быстро мы можем добавить все ключи в map'у - jmh даёт возможность защитится от множества скрытых подводных камней, связанных с работой VM - н-р если VM понимает, что результат выполнения никем и никогда не используется - так зачем и сам блок выполнения нужен - он может быть убран - и blackhole спасает от этого (хотя более простой способ - это просто вернуть объект или число из бенчмарк-метода - но оно всё равно попадёт в blackhole)

# Java Microbenchmark Harness (2)
можно указывать как долго надо разогревать VM, дабы исключить краевые эффекты связанные с jit компиляцией и не только, можно указывать как долго надо измерять сам бенчмарк, чтобы получить статистически корректные измерения, можно специфицировать в скольких нитях будет работать бенчмарк,

# Java Microbenchmark Harness (3)
по аналогии с junit можно специфицировать setup и teardown методы, которые соот-но вываваются раз перед и после работы тела бенчмарка, например, именно там я гружу из файла все найденные коллизии для строки username - всё это вспомогательные операции для самого бенчмарка

конечно - это не избавляет от того, чтобы писать неправильные benchmark-и и/или неправильно их трактовать - если ещё не делали - смотрите записи Алексея Шипилёва, где он подробно расскаывает о jmh, на сайте проекта есть подробные примеры.

словом - jmh - важный и полезный инструмент в руках инженера.

# "username" коллизии :: benchmark

Вернёмся к нашим "username"  коллизиям :
давайте сделаем такой benchmark - добавить ключи с коллизиями по строке username в hashmap, в setup методе - который я опустил - количество ключей, которое я загружаю - равно параметризованному size - т.е 1, 1000, 10 тыс и т.п

собственно проблема c коллизиями в hashmap и к чему это ведёт была описана в приведённой баге.

Так и что же у нас получается ?

# "username" коллизии :: java7 результаты

легко можно заметить параболу на графике - т.е квадратичная сложность - если честно - я не ожидал увидеть время отклика 1.5 минуты, передавая 200 тыс ключей.

Откуда пробелема возникла, думаю уже понятно - почти в самом начале я рассказывал про коллизии - и для их разрешения использовали подход, который называется chaining - по своей сути это просто linked list.

Если посмотреть как обрабатываются cookies, или параметры http-запроса в Tomcat'е - то там используется как раз LinkedHashMap - но для случая вставки ключей это ничем не лучше обычного HashMap. А после того, как все ключи из запроса будут загружены в map - приложение, или сервлет ищет нужный ему параметр - собственно поэтому я и выбрал в качестве ключа "username" - достаточно часто используемое имя параметра. А поиск ключа в мапе, в которой его нет, но есть много коллизий - заставит перебрать все ключи с одинаковым hashcode - а это ещё немного усугубит проблему.

И во время измерений я смотрел за загрузкой cpu - и на все эти 1.5 минуты одно ядро было загружено под 100% - доклад и конференция не про DOS-атаки, но идея думаю более, чем ясна.

И как всегда - главный вопрос - Что делать ? Кто нам поможет ?

# 23derevo

Да, это - Алексей Фёдоров - 2-3-дерево, надеюсь, что все узнали ?
java чемпион устраняет проблемы не взглядом , а своим добрым именем.

дело в том, что 2-3-дерево - как структура данных - изоморфна по своим свойствам красно-чёрному дереву. Минута занудства - 2-3 дерево - такое Б-дерево, у которого либо 2, либо 3 дочерних элемента, а красно-чёрное дерево это бинарное дерево поиска, в котором баланс осуществляется на основе "цвета" узла дерева. т.е цвет элемента в красно-чёрном дереве можно преставить как третий дочерний элемент у 2-3-дерева.

# Бинарное дерево поиска

для нас важно то, что красно-чёрное дерево является

бинарным деревом поиска,
самобалансированным два,
и относительно простым в реализации - три

всё это в итоге даёт нам структуру данных с логарифической сложностью как на операциях поиска, так и вставки и удаления.

И тогда мы будем разрешать коллизии с помощью такого гибрида из hash структуры и бинарного дерева поиска - в java начиная с 8ки - внутри HashMap, LinkedHashMap, ConcurrentHashMap используется красно-чёрное дерево при привышении некоторого порогового числа коллизий - пока уровень коллизий мал, то там по прежнему chaining.

# "username" коллизии :: map.put(key, key)

И вот как выглядит сравнение того же самого теста с коллизиями по username в 7ке и в 8ке - вот тот график, который слабо отличается от нуля - это 8ка - ибо там совершенно другой масштаб времени - положить все 200 тыс ключей на 8ке занимает где-то 100 мс

Кто ещё свои приложения в проде держит на 7ке ?  или на 6ке ?)

# "username" коллизии :: zoom-in 500x

если изменить масштаб в 500 раз - обратите внимание на шкалу времени - на это графике это миллисекунды - отклик 8ки почти линеен, а 7ка сразу ушла в небеса - точка возле 200 мс это при 1000 ключей

# "username" коллизии :: java8

И вот результаты работы тех же 200 тыс коллизий на 8ке в пересчёте на одну вставку - поведение графика чётко указывает на логарифическую сложность - типичная сложность древовидных структур

# "username" коллизии :: Comparable

Одно очень важное замечание - для того, чтобы строить деревья - ключи обязаны быть сравниваемыми - строки, числа, даты и многие другие объекты как раз сравниваемые - т.е реализовывать интерфейс Comparable, но если он не сравниваемый - то нас ждёт ещё более худшая ситуация.

Для сравнения я реализовал тот же бенчмарк, но в качестве ключа я использовал не java.lang.String, а класс-обёртку, но который НЕ реализует интерфейс Comparable.

И всё тот же набор ключей, полученный из коллизий по строке username.

Т.е. если вы каким-то образом получаете данные из не надёжного источника - н-р внешняя сеть - и по каким-то причинам используете свои классы - стоит рассмотреть возможность реализации Comparable - хотя не всегда это может быть и естественный порядок.

# утёкшая абстракция

Вообще это очень странно, когда корневой класс иерархии содержит в себе метод ради реализации ассоцитивного массива.
Например, существует интерфейс Comparable для сравнения объектов, но нет интерфейса Hashable.

Как вычислять hashcode у которого нет данных ? hashcode определён у java.lang.Object - значит все классы, которые не переопределяют этот метод - ведут себя точно так же. И что же собственно он возвращает ?

Надо сказать, что наличие этого метода у Object с реализацией по-умолчанию повлекло за собой последствия, из-за которых мы можем заглянуть в дебри виртуальной машины исследуя его.

# Urban Legend: Первоисточник
Первоисточником легенды является всё тот же javadoc к которому мы уже не раз обращались - и в нём сказано, что типичная реализация метода hashcode у java.lang.Object это преобразование внутреннего адреса объекта к числу.

Попробуем не только разрушить этот миф, но и наглядно показать, почему это не самый лучший выбор.

И так - предположим, что hashcode объекта это всё таки его адрес. В качестве инструмента будем использовать конечно же сам hashcode - и его свойства - неизменчивость и распределение значений. Будем проверять разные предположения на корректность при помощи тестов.

# Urban Legend
Если записать это что-то в виде Cи-кода, то это примерно выглядит так - взять адрес нашего объекта.

# Адрес объекта

Но вообще, первое, что приходит на ум, когда слышишь утверждение "hashcode использует адрес объекта" - это взять и проверить.
Но как надёжно получить адрес объекта ? Мало того, что hashcode это только 32 бита, а адрес объекта в современном мире 64х битных платформ - может быть запросто быть больше 32х бит.

# native method

Если мы посмотрим на исходный java код java.lang.Object - то увидим, что этот метод является native - т.е он реализован на уровне самой VM.

#      sun.misc.Unsafe

Может быть вы слышали хотя бы краем уха, а может нет - есть такой класс - sun.misc.Unsafe, который даже из названия предполагает, что использовать его не безопасно, так в общем-то оно и предполагось в sun - ибо в java он появился задолго до того, как Oracle поглотила Sun.
Словом, предполагалось, что это будет часть приватного API, только для внутренних нужд jdk, но уж слишком вкусные вещи есть внутри

например - можно выделить или освободить память как в старом добром Си, получение long и не только из объекта по некоторому смещению - и много ещё всякого фарша - но вот такого метода, чтобы получить адрес сразу нет.

# Unsafe :: адрес объекта (1)

Как я уже говорил - API приватный и всё, что делаете с ним - это только на ваш страх и риск. Этот объект нельзя просто так создать ни через оператор new - ни вызвав factory-method getInstance - обычно воруют уже существующий экземпляр через reflection.

# Unsafe :: адрес объекта (2)
А для того, чтобы получить адрес объекта - Применяется небольшая хитрость - создаём массив - и в него кладём исследуемый объект - и по смещению получаем адрес.

# Unsafe :: адрес объекта (3)
В общем-то ничего сложного, если бы не одно существенное но. Данный подход работает тогда, когда 64 бита, сжатие укзателей в java отключено, либо когда размер кучи куда больше 4гб.

и всё как всегда с арифметикой указателей - чуть промазали или не учли какой-то фактор - и сразу же боль.

Понятно, что для наших праздных целей посмотреть-да попробовать ничего страшного не случится, но как инструмент не выглядит надёжно.

# Java Object Layout

Нашу боль разделяют и люди в openjdk - и они создали инструмент, который позволяет проводить анализ компоновки объекта - расположение полей, сколько байт занимают - словом всё, что связано с его компоновкой.

И конечно же он сразу же из коробки даёт возможность получить - и адрес объекта, и его размер, можно достаточно просто снять дамп объекта и посмотреть его содержимое - без каких-либо Unsafe и прочей магии с головыми болями - всё это спрятанно как-то там внутри. В конце-концов авторы openjdk лучше знают и об внутреннем устройстве объекта, обо всех краевых случаях.

Словом - давайте забудем про Unsafe и будем использовать JOL.

# Адрес и hashCode

при помощи одного флага VM - мы можем добится того, что наше предположение будет истино.

Наглядней всего заметно сходство, если мы представим всё в 16 системе счисления - hashcode использует младшие 32 бита адреса, тут же и видим размер объекта - 16 байт.

Что же - теперь можно смело исследовать влияние такой реализации hash-функции и что мы можем увидеть через призму этого предположения.

# Следим за адресом объекта (1)

И первый эксперимент - проверить насколько можно доверять адресу объекта - для проверки этой гипотезы давайте создадим новый объект - theObject - в данном демо это будет главная цель нашего наблюдения - зафиксируем адрес этого объекта в самом начале

# Следим за адресом объекта (2)

затем будем создавать другие объекты и, чтобы избежать того, чтобы GC собрал их как мусор - будем хранить их в списке gcKeeper.

# Следим за адресом объекта (3)

Основная цель - следить за адресом объекта theObject - как только адрес изменится (а может он никогда не изменится?) мы выйдем из цикла и прекратим создавать объекты.

Поскольку наши объекты не могут быть собраны - у нас есть все шансы получить OOM, если адрес не поменяется.

И так - голосуем - кто за OOM ? А кто за то, что адрес объекта изменится ?

(Открываем и показываем **ObjectReallocation** - Запускаем **ObjectReallocation** и смотрим демо.)

Что произошло ??? Почему ?

# Следим за адресом объекта вместе с GC

Давайте добавим дополнительный флаг для запуска VM - а именно будем отслеживать GC и запустим то же самое демо

(Запускаем **ObjectReallocation (gc)** и смотрим демо.)

Теперь видно, что произошла сборка мусора - и более того, по GC логу можно даже понять откуда и куда был перемещён наш объект - чуть позже мы это рассмотрим подробнее.

# GC: поколения
Все слышали про поколения в сборке мусора ? Поднимите руки. кто не слышал ? и теперь - кто слышал ?

Давайте бегло объясню общую идею - Много лет назад была высказана гипотеза, что большинство объектов короткоживущие - т.е умирают вскоре после того как они были созданы - буквально слоган панков - жить быстро, умереть молодым. И для того, чтобы сборщику мусора обходить не весь граф объектов - он обходит только очень малую часть.

Т.е объекты рождаются в eden, если он не умер молодым, то он перемещается в более старшее поколение - survivor, и потом может быть перемещён в старое поколение - old generation, куда сборщик мусора почти заходит очень редко - другими словами Full GC случается редко.

java использует эту гипотезу о поколениях - и в общем-то она не плохо даже работает - но с ростом объёмов памяти и ростом объектов гипотеза уже не так удачно работает как раньше - не так давно стали появлятся другие гипотезы - как например региональная гипотеза, которая реализована в G1 и shenandoah.

# GC - не только сборка мусора

Эксперимент как раз показал, что сборщик мусора он не только собирает мусор, но и осуществляет перемещение объектов между поколениями - те, кто пережил несколько минорных сборок попадают в более старшие поколения - и чаще умирают молодые. Мы же его принудительно поместили в gcKeeper, дабы предотвратить сборку мусора.

Объект изначально был в eden - и GC переместил его за пределы eden - и мы это заметили.

# Следим за hashcode

Изменение адреса объекта, порождает следующий эксперимент - если может изменится адрес - то возможно может и hashcode изменится - мы же помним, что hashCode это адрес объекта, да ?

По сути делаем всё то же самое, что и в предыдущем эксперименте, только на этот раз будем следить не за адресом объекта, а hashcode - так же зафиксируем начальное значение, и так же будем создавать новые объекты и хранить их в gcKeeper пока не изменится hashcode, либо не случится OOM

И так же как и в предыдущем демо размер кучи уменьшил до 256Мб.

Голосуем - Кто за то, что hashCode изменится ? Прошлый же раз адрес поменялся, а hashcode это же адрес, так ведь ?  А кто за OOM ?

(опять показываем код **ObjectHashReallocation** - так же как и в предыдущем демо - отличие от слайда только в сообщении после цикла - Запускаем **ObjectHashReallocation** и смотрим демо.)

Что случилось ? Почему ?

Объект не может нарушать контракта hashcode, hashCode является собтсвенностью объекта, более того - неизменяемой собтсвенностью.

Напрашивается вывод, что данное свойство является

# Скрытое свойство

Скрытым свойством - Как мы помним - hashcode это native метод, но на уровне java кода ни одного свойства у java.lang.Object не определено. И нам надо идти глубже, и поможет нам в этом снова Java Object Layout !

Давайте при помощи JOL сделаем dump объекта - т.е как объект целиком представлен в памяти.
(demo)?

# Дамп объекта

Ох ты ж! Мало того, что hashcode является адресом - так он же ещё и записан в заголовке объекта !

обратный порядок байт в дампе обусловлен тем, что это всё сделано на Intel, который использует Little-Endian порядок, т.е порядок от младшего к старшему байту.

Т.е что происходит - hashcode вычистяется как младшие 32 бита адреса, а потом он записывается в заголовок объекта, после чего адрес объекта уже может менятся, а вот уже hashcode нет.

Т.о. предыдущие два эксперимента нам показали, что в какой-то момент времени hashcode объекта таки может быть адресом, но адрес является ненадёжным свойством и его - т.е hashcode надо где-то хранить.

Мы очень сильно отвлеклись с разбирательством адрес - хэшкод, казалось бы можно было бы на этом слайде и закончить - доказывать и опровергать больше нечего. Но мы выбрали хэшкод как наш проводник в мир внутренностей vm и мы всё же хотим показать почему это не самый лучший способ определения хэш-функции.

# Сколько влезет в кучу ?

продолжим наше разоблачение - следующий эксперимент, которые мы можем сделать голыми руками без каких-либо дополнительных инструментов - это попробовать найти коллизии hashcode используя в качестве источника адрес.

Как и в прошлых экспериментах мы используем размер кучи до 256 Мб, часть съест сама vm - и уже зная размер объекта - получается, что в память влезет около 15 млн объектов - что значительно меньше максимально возможного положительного значения hashcode - 2х млрд

и казалось бы и коллизий по hashcode никто не ожидает увидеть.

# Молодое поколение

Увы, но это слишком наивные рассуждения - и уже из предыдущего опыта мы видели, что объекты создаются в eden, который в нашем случае оказался равен 64Мб - и в этом случае нам удастся создать только 4млн объектов, после чего начнутся коллизии.

# Граница коллизий

И так сам эксперимент по поиску границ коллизий hashcode - основное действо происходит в цикле - будем создавать объекты, и каждый новый объект будет получать новые адреса памяти. Нашим противником как всегда выступает GC - может взять и удалить объект, на который больше никто не ссылается - и соот-но какой-то иной объект может использовать адрес для нового объекта. Чтобы избежать этого - мы будем хранить все созданные объекты в gcKeeper. а уникальные значения будем хранить в uniqueHashCodes - чтобы избежать autoboxing и прочих паразитных аллокаций будем использовать trove collections, которые умеют хранить примитивы, но у Trove Set такой же контракт на добавление, как и у java.util.Set - если такого значения ещё нет в сете - то вернётся true - и false в противном случае. Для демо вполне хватит и 10 коллизий.

хотя - может быть наши рассуждения не корректны и никаких коллизий не увидим и случится OOM.

Голосуем - Кто за OOM ? А кто за коллизии ?

(Показываем код **IdentityHashCodeCollision**, - Запускаем **IdentityHashCodeCollision** и смотрим демо.)

# Граница коллизий - Результаты

Произошли коллизии, как мы и ожидали - немного меньше, чем мы предсказывали - мы не учитывали, что наши вспомогательные хранилища займут место под этот самый миллион + во время работы хранилища ещё расширялись - что тоже привело к дополнительным расходам, но как бы то ни было - порядок коллизий совпадает - и увы и ах - только 2 млн уникальных значений.

# пространство hashCode

И так, выбрав адрес в качестве hashcode мы потеряли 10 бит - и из 4х млрд у нас остаётся только 4 млн уникальных значений.

# Граница коллизий - Результаты

Из предыдущего эксперимента по нахожению границ коллизий мы не только потеряли 10 бит в hashcode -  но ещё заметили из коллизий стал видено в общем-то ожидаемый шаблон - после того, как встретили первую коллизию - hashcode начинают строго повторять адреса Eden - более того, разница между адресами - 16 байт - здесь все коллизии приведены так же в 16 системе счисления.

Поскольку мы имеем дело с адресами, и созданием объектов - сделаем ещё одно отвлечение и рассмотрим вопрос выделения памяти.

Смотрите - в начале мы не задумывались о том, что объект может быть перемещён и утвержение, что hashCode это адрес не выглядило как-то странно, когда мы стали разбираться - нашли несоответствие. Теперь же у нас коллизии ограниченны eden - но действительно ли это всё, что мы знаем ?

# Упрощённый memory allocation

Каждый раз, когда вы создаёте новый объект вы фактически резервируете некоторый объём памяти. И задачей выделения и резервирования памяти занимается аллокатор - простейший случай выглядит так - считаем, что адреса начинаются от 0 и до memoryPointer уже заняты - если мы хотим попросить ещё немного памяти - то сдвигаем границу memoryPointer и так мы зарезервировали объем памяти от старой границы размером size.

На первый взгляд именно такой аллокатор в действии только что и видили.

Хорош ли такой malloc - что вообще не так с ним ? Есть ли критические замечания ?

# SyncAllocator
Да, предыдущая версия совсем не годилась для работы с многопоточностью и synchronized безусловно теперь её гарантирует.

И логично посмотреть как себя ведёт данный allocator

# SyncAllocator Performance Benchmark

такой вот простой бенчмарк, чтобы измерить производительность нашего аллокатора - и это на 10 потоках - в реальных приложениях их намного больше - и такой же самый бенчмарк был сделан, но для однопоточного аллокатора

и здесь, и далее я буду использовать схожие графики для сравнения производительности - единица измерения нс на операцию - т.е чем меньше нс тратится на операцию, тем быстрее, и значит лучше.

при 10 параллельных нитях - почти 400нс на одну аллокацию - это очень дорогая аллокация - для сравнения single-threaded allocator, хотя он применим только к однопоточному случаю, почти в 100 раз дешевле - пока это будет наш ориентир

# Можно ли лучше ?

Можно ли лучше ? Есть какие-нибудь идеи ?

# Compare-and-Swap

Кто-нибудь слышал про Compare-and-Swap ? CAS это операция атомарного сравнения-и-изменения значения, которая реализованая на многих железных архитектурах

# CAS Allocator
Так давайте же сделаем allocator на основе CAS - AtomicLong как раз представляет обёртку вокруг cas для операций с long - getAndAdd атомарная операция на основе CAS'а - получаем старое значение и увеличиваем на size.

и как всегда померяем - стало ли лучше ?

# Allocators Performance Benchmark
Так же 10 нитей - стало лучше, но не сильно лучше - 245 нс на операцию очень дорого - мы всё так же далеки от идеала.

Вообще сравнивать производительность в 10 нитях и в одной - не совсем корректно - слишком уж грубый ориентир - можно же выбрать более достоверный ориентир.

Сравним наш моделируемый эксперимент с реальным выделением памяти - т.е как сама VM выделяет память.

# Java Allocation

Опять простой бенчмарк и так же в 10 нитях - как мы помним размер объекта 16 байт - и теперь наше моделирование по условиям измерения очень близко к реальному случаю.

и результаты, которые наглядно демонстрируют, что наша модель очень далека от реального случая.

# Можно ли ещё лучше ?

Определённо хочется улучшить нашу модель аллокатора.
У нас уже есть некоторое понимание того, что адрес как hashcode - это не очень хорошая хэш-функция, потому, что много коллизий. Коллизии это тоже не плохой инструмент для исследования, такой хороший молоток.

# Границы коллизий :: многопоточный (1)

Так вот давайте этим молотком постучим - как стало ясно из эксперимента с границами коллизий - они вызваны размером eden. Как распределяется hashcode в случае нескольких потоков ?

Давайте соорудим похожий эксперимент, только работающее в нескольких нитях -

# Границы коллизий :: многопоточный (2)

Т.е так же, как и в предыдущем эксперименте - основное действие происходит в цикле - создаём новый объект, и не даём GC его собрать - и собираем уникальные hashcode.

# Границы коллизий :: многопоточный (3)

и будем работать до первой коллизии - не важно, в какой из нитей она бы не произошла.

# Границы коллизий :: многопоточный (4)


Поскольку в многопоточном режиме вполне возможно разбегание - какая-то нить создаст больше объектов, какая-то меньше - мы будем делать каждый следующий шаг почти синхронно с другими нитями - в этом нам поможет Phaser - одна из реализаций шаблона синхронизации Барьер.



так же как и ранее будем избегать всякие паразитных аллокаций - заранее преаллоцируем место для объектов - исходя из раннего опыта - и будем просто записывать состояние распределения адресов каждый шаг - и как только случится коллизия - тут же прекратим работу - и уже после этого посмотрим где и как они произошли.

Но, потенциально может и OOM произойти - кто за OOM ? Теперь более щипетильный вопрос - а как будут распределены адреса ? Мы же ожидаем, что eden равномерно делится несколькими нитями - каждый шаг мы создаём по одному объекту - а phaser даёт нам ту самую гарантию, что ни одна нить не убежит вперёд других, больше, чем на один наг.

Какие наши ожидания ? Предыдущий опыт нам показал, что память выделяется последовательно и разница равна 16 байтам - т.е размеру объекта.

Голосуем - Кто за то, что разница будет 16 байт (или быть может +- 1 объект) ? Может есть кто не согласен и увидим другое ?

(показываем код **ThreadedIdentityHashCodeCollision** - несколько различий между слайдом - количество потоков получаю как аргумент для запуска приложения - запускаем демо **ThreadedIdentityHashCodeCollision 4** на 4х нитях - и чтобы была многопоточность, и чтобы для демо не слишком много)

Как и ожидали - случились коллизии, а не OOM - и даже суммарно порядок совпадает

# Распределение hashCode по нитям

Вот чего не ожидали, так это такой большой разницы?

И так - у меня две новости - одна плохая, и хорошая.

Хорошая в том, что hashcode объектов в каждой нити сильно отстоят друг от друга - т.е адресные пространства нитей отделеный друг от друга - это нам пригодится для улучшения нашей модели аллокатора.

# Плохая новость

И плохая новость в том, что мы смогли создать только 400тыс объектов на одну нить - таким образом мы теряем ещё примерно 3 бита.

# Даёшь БОЛЬШИЕ куски памяти ! (1)

Вернёмся же к модели аллокатора - и напилим такой аллокатор, который будет резервировать память большими кусками синхронно, а внутри потока он будет работать как старый добрый простейший однопоточный.

Да код не такой уж читаемый - SIZE - это размер большого куска - для примера 1Мб

# Даёшь БОЛЬШИЕ куски памяти ! (2)
- memoryPointer такой же как и в cas-allocator - граница занятой памяти, которую будем менять с помощью cas'а

# Даёшь БОЛЬШИЕ куски памяти ! (3)
- а в threadLocal у нас будет лежать объект, хранящий значения об использованной памяти внутри нити.

и снова померяем - стало ли лучше ?

# Allocators Performance Benchmark

Круто - вот это уже выглядит намного лучше. Опять же все в 10 нитях, кроме single-threaded.

# Thread Local Allocation Buffer

Собственно подобным образом и ведёт себя аллокатор в java, используя Thread Local Allocation Buffer - каждая нить запрашивает кусок памяти из Eden, и внутри своей нити уже выдаёт без каких-либо блокировок - маленькая проверка - не вышли ли мы за пределы зарезервированного объёма.

# Thread Local Allocation Buffer
Когда один TLAB заполнен - запрашивается другой кусок - через блокировки - может быть чуть большего размера

Когда нельзя уже больше выделить новый кусок TLAB - случается GC - он решает, что делать с объектами - убивать или перемещать их в другое место. При этом весь Eden снова чист - и после чего TLABы снова могут пилить Eden.

# Границы коллизий :: многопоточный :: БЕЗ TLAB

И теперь запустим то же демо **ThreadedIdentityHashCodeCollision 4 -TLAB**, но на этот раз отключив TLAB - и снова жанглируя с флажками JVM

# Распределение hashCode по нитям БЕЗ TLAB

Теперь видно, что разница ровно 16 - т.е равна ровно размеру объекта - по сути мы находимся в режиме синхронизированного аллокатора, который на каждую аллокацию выделяет из кучи ровно столько байт, сколько необходимо для объекта.

# Стоимость TLAB

И в завершении темы аллокаций осталось только померять насколько эффективно использование TLAB.

# Стоимость TLAB - результаты
Так же, как и моделируемом аллокаторе я использовал 10 нитей - и заметно насколько аллокакция с TLAB лучше, чем без неё - почти в 100 раз

# 32bit → 19bit

Итак, подведём итоги экспериментов - использование GC и идеи поколений, быстрой аллокации и TLAB приводят к тому, что hashCode из 32х бит потерял большУю часть. Коллизии начинают встречаться уже через какие полмиллиона новых объектов, после чего все значения строго повторяются.

Мы сами загнали себя в угол с идей использовать адрес в hash-функции - плохая выходит hash-функция с очень большим числом коллизий.

# Может быть Random ?
Может быть ну его нафиг и взять какой-нибудь генератор случайных чисел ?

Что будет с коллизиями в этом случае ?

Вообще насколько должна быть большой набор ключей, чтобы хотя бы у двух каких-либо ключей совпал hashcode ?

Зал, есть идеи ? Нет, ну это очевидно, когда у нас будет 4 млрд значений - то со 100% вероятностью, что хотя бы одна коллизия да будет.

# Парадокс дней рождения
Ответ даёт нам парадокс дней рождений - в группе уже из 23х человек, с вероятностью 50% др совпадут у двух человек. Используя общую формулу мы получим дикие числа - особенно 2^32 факториал - конечно, вольфрам альфа это могут посчитать, но существует формула приближения

так, что не мучаемся - подставляем и считаем - на удивление это всего лишь 77 тыс.
Т.е, если у нас есть 77 тыс ключей, то с вероятностью 50% у двух ключей совпадут hashcode - но не как в случае с адресом, когда значения начнут после некоторого порога строго повторяться.

# -XX:hashCode

Дамы и Господа, Ladies and Gentelmen - пришло время открыть карты - это была ловкость рук и никакого мошенничества - умелое жонглирование с параметрами виртуальной машины!

По-умолчанию hashcode в java это всё-таки просто случайное число и все предыдущие демо были проведены с режимом, когда hashcode вычисляется на основании текущего адреса объекта для того, чтобы показать насколько абсурдна эта идея и что есть много других, более серьёзных и важных задач в архитектуре, чем увязывать hashcode и адрес

Этим флагом можно переключать vm в разные режимы генерации hashcode - раньше, до 8ки, по-умолчанию эта был 0ой режим - использоваться генератор псевдослучайный чисел Парк-Миллера, а начиная с 8ки используется 5ый режим - генератор псевдослучайных чисел Марсальи.

Для предыдущих экспериментов, где требовалось, чтобы работало предположение, что hashcode это адрес - я использовал режим №4 - 1ый режим по своей сути ничем принципиально не отличается от генерации на основании адреса. И режим №2, который возвращает всегда единицу - хорошее испытание для работы алгоритма по разрешению коллизий.

# Дамп объекта при -XX:hashCode=5
В доказательство можно посмотреть дамп памяти объекта при флаге по-умолчанию, т.е hashCode = 5. Да, хэшкод хранится всё так же хранится в заголовке объекта, но с адресом никак не связан.

# Распределение hashCode
И на последок, для наглядности сравним гистограму распределения hashcode - по адресу - красным, и на основе генератора случайных чисел - синим

Как и ожидали раньше - hashcode от случайного числа равномерно распределен по числовой оси, да есть коллизии - их около 23 тыс
И hashcode на основании адреса - в очень узкой полоске, которая соответсвует адресному пространству eden - и количество коллизий чуть больше миллиона

# Beyond the legend

Всё! С мифом о Object.hashcode покончили.

# String join

И пожалуй последняя тема, которая на первый взгляд никак не связана с hashcode.

Думаю всем когда-то приходилось склеивать строки и писать что-то подобное, не так ли ?

# StringBufferPerfTest

И давайте напилим такой вот бенчмарк

Два разных буфура, добавляем одну букву, и получаем строку.

Да, и второго буфера ещё вызовем System.identityHashCode - но это только в setup методе, т.е один раз перед всеми измерениями, даже ещё до разогрева.

Это всё в одной нитке - Какие будут ожидания ? Кто быстрее ? +- одинаково, не так ли ?

# StringBufferPerfTest результаты

Неожиданно ? Опять какая-то магия и мистификация ?

# Biased Locking

Не редко бывает так, что объект является thread-safe, но по факту он используется почти всегда одной нитью, и очень редко когда какая-то другая нить захватыает его монитор.

У StringBuffer все методы синхронизированы - и наш тест работает в одном потоке - т.е это именно наш случай.

Захват от отпускание монитора это не дешевые операции - поэтому изыскиваются возможности как облегчить. А что если не сделать так - если монитор уже был захвачем данной нитью - то как-то его пометить, привязать к этой нитке. Это и есть основная идея Biased locking.

Вопрос в том где размещать эту метку нити ? И как всегда нам поможет JOL

# Biased Locking demo

И так - создаём объект и снимаем его дамп - в нулевой момент времени в заголовке объекта вообще ничего нет

# Biased Locking demo 2

После того как мы захватываем монитор объекта в заголовок объекта записывается id нити - id нити можно получить, например, используя thread dump или инструментами типа jvisualvm

# Biased Locking demo 3

И стоит нам вызвать System.identityHashCode - как он отзывает biased locking и запишет себя в заголовок объекта - и так же поменяет флаг в первом байте - который как раз и говорит - что теперь это объект с системным hashcode - после это biased locking больше уже не работает для данного объекта.

И в таком случае захват монитора снова становится дорогим.

# Заключение

И капитанство в заключении -

* Hash структуры данных это одни из быстрых структур данных,
* Используя свои собственные ключи - не забывайте переоределять не только hashcode и equals, но и серьёзно рассматривайте возможность реализации интерфейс Comparable - это защитит вас в случае средне-плохого универсального способа вычисления hashcode - новой редакции Effective Java пока ещё нет, но я больше, чем уверен - это будет там.
* Хотите, чтобы было ещё лучше и меньше коллизий - исследуйте свои hash-функции не только на предмет абсолютных коллизий, но и на предмет коллизий после мастшабирования на размеры массива - это может сократить расход памяти.
* И просто жанглируя флагами vm из протёкшей абстракции Object.HashCode можно увидеть уши нескольких отличных инженерных решений в архитектуре - это и копирующий GC, и быстрые аллокации, и облегчённый завхат монитора, но не злоупотербляйте System.identityHashCode.
* И уж точно можно сказать - hashcode это не адрес объекта. По крайней мере, по-умолчанию.

# Контакты

Все демо и слайды доступны на github-е

Спасибо.

