# preparation

* Idea
    * default (белая) тема
    * отключить show whitespaces
    * presentation mode
* MacOsX settings
    * Dock - automatically hide and show Dock
* Выключить все IM!

# Urban Legend: HashCode

Меня зовут Владимир и я буду рассказывать легенду о hashcode.

# план

* в начале немного откровенно покапитаню - вспомним теорию и напомню тем, кто уже знает, или расскажу тем, кто ещё не знает - некоторые структуры данных - списки и ассоциативные массивы - на примере создания простейшего телефонного справочника.
* затем серьёзно окунёмся в потроха виртуальной машины при помощи всё того же hashcode - будет и сборщик мусора, и аллокация, будут и баттлы
* поговорим про правила вычислений hashcode для реальных данных
* и как можно используя знания о hashcode устроить DoS атаку, и как вылечить её
* и на последок ещё один трюк виртуальной машины и как hashcode может всё изменить

# Телефонная книга
Попытаемся разобратся на примере телефонной книги, что такое ассоциативный массив - пусть у нас есть пара ключ - значение. Ключом будет выступать имя или псевдоним человека, а значением будет его номер телефона.

Для начала давайте добавим в нашу книгу несколько уважаемых адресатов.

# Добавить Барух
Конечно же первым делом добавим Баруха!

Для этого у нас есть массив ключей, и массив значений, куда мы заботливо запишем наш первый контакт.

# Добавить Шипилёва
Затем Алексея Шипилёва,

# Добавить 23derevo
И Алексея Фёдорова 23дерево.

И так - добавлять мы уже научились, давайте теперь попробуем

# Найти 23derevo - jbaruch

Найти человека из нашей телефонной книги, например Алексея Фёдорова 23derevo

Для этого перебираем все доступные имена - и сравниваем с искомым ключом.

Барух это не Лёша, идём дальше

# Найти 23derevo - shipilev
Это Шипилёв- опять идём дальше

# Найти 23derevo - 23derevo

И вот наконец мы нашли Лёшу Фёдорова

# Найти

Наш поиск это полный перебор массива имён (т.е ключей).

Если таким образом построить телефонную книгу большой компании, в которой работает несколько тысяч человек - то поиск в ней будет долгим. И надо сказать, что подобных задач много - словари - или dictionary - это, кстати, название ассоцитивного массива в англоязычной среде, и подсчёт уникальных событий - например, подсчёт слов в статье, и т.д. И поскольку это часто встречаемая задача - то и решить её хочется не брутфорсом, не с линейной сложностью - а как-то поэффективней.

# Можно ли что-нибудь сделать лучше ?

 Есть какие-нибудь предложения ???

 (возможно - бинарное дерево поиска)

# Hash!

Да, одним из ответов - это использования хэша. Введём функцию, которую назовём hashCode, ставящую в соответствии с ключом некоторое числовое значение. Тогда отмасштабировав полученное число на длину массива мы можем сказать, куда этот ключ в массиве надо записать.

# javadoc
Более того - в java такая функция уже определена - причём у самого корневого класса - у java.lang.Object

Круто! Постороим же теперь телефонную книгу используя hash фунцию.

# Добавить Барух
Как всегда первый у нас Барух! И его hashcode, конечно же, +100500 - не меньше! Масштабируем 100500 на длину массива 7 и получаем индекс = 1

# Добавить Шипилёва
HashCode Лёши Шипилёва 42, что как бы намекает на то, кто знает главный вопрос жизни, вселенной и всего такого.
Опять же масштабируем и индекс в массиве - 0.

# Добавить 23derevo
И теперь Лёша Фёдоров 23дерево, очевидно, его hashcode 23 - и его место в массиве 2.

Пока всё выглядит не очень-то сложно и даже чем-то похоже на то, что мы видели раньше - как же дело обстоит с поиском ?

# Найти 23derevo
А выглядит всё очень даже прилично - hashCode 23derevo = 23, индекс 2 и voi la - сразу же номер Фёдорова нашли.

# Найти Медведа
А вот поступил вопрос - какой номер у медведа - конечно нам с вами очевидно, что он явно не из благородных донов, но всё же. Пусть его hashcode 51, масштабируем 51 на длину нашего массива - и что у нас тут ? Лёша Фёдоров - сравниваем имена - очевидно не равны - всё - нет никаких медведов и телефона его тоже не знаем.

# сложность
т.е алгоритм поиска это вычисление hashcodе нашего ключа, его масштабирование до размеров массива и проверка ключа.
т.е никак не зависит от длины массива - сложность получается константа.

круто, не так ли ?

# неспокойоный Барух
Но вот беда беда - кто-то поменял hashCode Баруха и теперь он почему-то стал 11 - и если теперь мы попробуем найти его в нашей телефонной книге - то мы просто не найдём Баруха.

И зачем нам вообще тогда этот hashCode нужен, если могут случаться такие сюрпризы - как можно вообще потерять Баруха !? уж лучше долго, лучше старым добрым перебором, но таки найти адресата.

Но нам же как хочется - и на ёлку влезть, и на ракете покататься.

# Контракт hashCode

Надо жёстко ограничить такое поведение - поэтому определим контракт для hashcode - сколько бы раз не вызывали ли мы hashCode он должен постоянно возвращать одно и то же значение hashcode.

# Разбор Полётов

И тут случается полный Разбор Полётов - приходят Витя Гамов, Антон Архипов и Алексей Абашев - и у всех, конечно же, как и у Баруха hashcode +100500 - и все претендуют на то же место, что и Барух. Что будет, что будет ?

# Будет ли драка ?
Будет ли драка за место ? Или не будет ? Зал, кто за драку ? Или все против ?)

# Драки не будет - но будет снова список

Драки конечно же не будет - Витя Гамов, Барух и сотоварищи просто устроят подкаст, а возникшую коллизию - т.е совпадение hashcode придётся как-то решать - ситуация не приятная, но типичная. Один из способов её разрешить - chaining - это создать список и поместить все ключи с одинаковыми hashcode в него.

И сложность поиска в случае, когда коллизий много снова становится линейной. Это очень важный момент - коллизии способны сломать производительность, и чем больше коллизий, тем только хуже операции типа поиска, вставки и т.п

# утёкшая абстракция
Вообще это очень странно, когда корневой класс иерархии содержит в себе метод ради реализации словаря.

Например, существует интерфейс Comparable для сравнения объектов, но нет интерфейса Hashable. Словом наличие метода hashcode у Object с реализацией по-умолчанию повлекло за собой последствия, из-за которых мы можем заглянуть в дебри виртуальной машины исследуя его.

# Urban Legend: Первоисточник
Это была присказка, а сказка впереди.

Первоисточником является всё тот же javadoc к которому мы уже не раз обращались - и в нём сказано, что типичная реализация метода hashcode у java.lang.Object это преобразование внутреннего адреса объекта к числу.

# Urban Legend
Если записать это что-то в виде Cи-кода, то это примерно выглядит так - взять адрес нашего объекта.

Конечно круто одно дело написать, а другое дело проверить. есть проблема - в самом языке java нет адресной арифметики, поэтому придётся как-то выкручиваться для того, чтобы получить адрес объекта.

# Unsafe ?
И вот Алексей Шипилёв не двусмысленно намекает - есть же могучий Unsafe - открывающий доступ к святая святых - к внутреннестям jvm. Но мы же крутые парни, не так ли ? мы же все любим unsafe !

# sun.misc.Unsafe

Так вот примерно выглядит получение адреса объекта, используя sun.misc.unsafe - ещё опущен момент, как собственно надо через reflection своровать экземпляр unsafe - его нельзя просто так создать через new. Более того тут лишь частично учтены несколько краевых случаев - когда размер кучи меньше 4гб и больше - а так же 32х битная java или 64х битная - стоит чуть ошибится и мы получим не адрес объекта, а не пойми что - в общем, всё как всегда с адресной арифметикой.

Выглядит ужасно - особенно этот случай, когда работают сжатие указателей на размере кучи до 4х гб. да ещё и нужно знать размер укателя и не совсем понятно как его получить, даже используя unsafe.

Не удивительно, что Алексей на предыдущем слайде с явным пренебрежением посматривал на нас.

Что рекомендуют специалисты ? Может быть есть что-то понадёжней и поудобней ?

# Правильный ответ - Java Object Layout

Конечно есть - и имя ему JOL - собственно всю эту магию с unsafe он делает где-то там внутри, все эти случаи с 4гб, 32битами или 64 - просто получаем адрес без лишней головной боли.

# Адресное пространство объекта

Стоит ещё заметить, что все адреса выровнены на 8 байт - это сделано из соображений производительности и работы памяти - в общем мы видели магию на слайде с unsafe - со сдвигом адреса на 3 бита. Т.е выбирая адрес в качестве hashcode мы сужаем колечиство возможных вариантов с 32бит до 29.

# Переезд Баруха: OOM vs RuntimeException

И первое демо - создадим новый объект - и назовём его Барух - затем будем создавать другие объекты и добавлять в общую тусу, при этом будем отслеживать за адресом Баруха.

В общем у нас два выхода - либо вывалимся с OOM, либо с RuntimeException. В целях демонстрации я немного тут подкрутил флаги jvm - уменьшил размер кучи до 256Мб - чтобы не ждать долго OOM.

Кто за OOM ? А кто за RuntimeException ?

(Показываем код **ObjectReallocation**, отличие только в сообщении в RuntimeException - Запускаем **ObjectReallocation** и смотрим демо.)

Что произошло ??? Почему ?

# Переезд Баруха и Тов. Мусорщик
Случилась сборка мусора, которая и переместала наш объект - ловкость рук и немного дополнительных ключей для запуска jvm - с этими ключами мы получим информацию о работе сборщика мусора - и снова смортим демо.

(Запускаем **ObjectReallocation (gc)** и смотрим демо.)

Теперь видно, что произошла сборка мусора - и более того, можно даже понять откуда и куда был перемещён наш Барух.

# Переезд Баруха и Тов. Мусорщик (детализация)

Все слышили про поколения в сборке мусора ? Кто не слышал ???

Много лет назад была высказана гипотеза, что большинство объектов короткоживущие - т.е умирают вскоре после того как они были созданы - буквально слоган панков - жить быстро, умереть молодым. И для того, чтобы сборщику мусора обходить не весь граф объектов - он обходит только очень малую часть. если объект не умер молодым, то он перемещается в более старшее поколение - survivor, и потом может быть перемещён в старое поколение - old, куда сборщик мусора почти заходит очень редко - другими словами Full GC случается редко.

java использует эту гипотезу о поколениях - и в общем-то она не плохо даже работает - но с ростом объёмов памяти и ростом объектов гипотеза уже не так удачно работает как раньше - не так давно стали появлятся другие гипотезы - как например региональная гипотеза, которая реализована в G1 и shenandoah.

Eden - т.е молодое поколение, где создаются все объекты - его адреса вы получили как раз из логгирования сборщика мусора - и зная старый и новый адрес Баруха видно, что раньше он был в Eden, а после сборки оказался вне его - оно в общем-то и так понятно - Барух не молодой мальчик, а вполне себе зрелый спикер.

Важный момент - сборщик мусора он не только собирает мусор, но и осуществляет перемещение объектов между поколениями - те, кто пережил несколько минорных сборок попадают в более старшие поколения - и чаще умирают молодые. Собственно для этого мы помещали нашего Баруха в List туса - чтобы его не удалили.

# Смена hashCode Барухом: OOM vs RuntimeException
И ещё одно демо - мы будем делать всё то же самое, только следить мы будем теперь за изменением hashcode. Мы же помним, что hashCode это адрес объекта, да ?

И снова два варианта - либо OOM, либо с RuntimeException. Так же, как и в предыдущем демо размер кучи уменьшил до 256Мб.

Кто за RuntimeException ? Прошлый же раз был RuntimeException, а hashcode это же адрес, так ведь ?  А кто за OOM ?

(опять показываем код **ObjectHashReallocation** - так же как и в предыдущем демо - отличие от слайда только в сообщении в RuntimeException - Запускаем **ObjectHashReallocation** и смотрим демо.)

# Девушку из деревни

Можно вывезти девушку из деревни - а вот деревню из девушки никогда. Объект не может нарушать контракта hashcode, hashCode является собтсвенностью объекта, более того - неизменяемой собтсвенностью.

# О, где же ты, брат ?

Так где же ты, брат ? У объекта нет ни одного свойства - по крайней мере на уровне java. Но у нас есть понимание того, что адрес объекта может поменятся, а hashcode нет - стало быть он должен где-то быть записан.

# We need to go deeper

Что же - нам надо идти глубже, и поможет нам в этом снова не Unsafe, а JOL !

Давайте при помощи JOL сделаем dump объекта - т.е как объект целиком представлен в памяти.
(demo)?

# Дамп объекта

Ох ты ж! Мало того, что hashcode является адресом - так он же ещё и записан в заголовке объекта ! Т.е что происходит - hashcode вычистяется как младшие 32 бита адреса, а потом он записывается в заголовок объекта, после чего адрес объекта уже может менятся, а вот уже hashcode нет.

# Навалим в кучу

И давайте оценим сколько мы сможем наплодить объектов, прежде, чем свалимся c OOM ?
Кучу мы ограничили до 256Мб, сколько-то заняла сама виртуальная машина, итого осталось свободно около 230 Мб, поделив на размер объекта - получаем около 15 млн.

Помните, что hashcode это int, который 32 бита, но адреса выровнены на 8 байт, итого hashcode достаётся 29 бит, а это около 0.5 млрд, что значительно больше 15млн. Т.е. если мы будем давать объектам hashcode на основании адреса - то коллизий мы не увидим - по крайней мере на таком размере кучи, так ?

Возражения есть ?

# Молодое поколение

Да, главное возражение - это то, что мы находимся в молодом поколении - как мы уже видели ранее по переезду Баруха - все объекты создаются в Eden - и из того же самого лога GC мы видим, что размер eden 64Mb.

И т.к. hashcode использует адрес, а все объекты создаются в Eden - то и количество уникальных значений будет равно кол-ву объектов, которые мы можем там создать - после чего адреса снова начнутся повторятся.

т.е где-то 4 млн объектов сможем создать.

# Драка за hashCode: OOM vs RuntimeException
Давайте проверим это - очередное демо.

Чтобы избежать всяких autoboxing и прочих неожиданностей связанных с экспериментом - мы будем использовать trove collections, которые хранят примитивы, и внути это просто честный массив

Демо - опять будем создавать много объектов, только теперь мы будем проверять есть ли совпадения по hashcode - будет ли драка в тусе за hashcode ?

Что случится раньше - OOM или коллизия ? Кто за ООМ ? А кто за RuntimeException ?

(показываем код **IdentityHashCodeCollision** - небольшие отличия от того, что на слайде - дабы исключить нежелательное потребление памяти, связанное с необходимостью расширять массивы внутри ArrayList и TIntHashSet - запускаем демо **IdentityHashCodeCollision**)

// Может быть ещё на G1?

видим, что мы создали немного меньше, чем ожидалось - возможно это из-за того, что часть памяти отъели накладные расходы демо - на ArrayList и trove set. но по крайней мере совпадает порядок.

# пространство hashCode

итого из 4 млрд значений, 3 бита съело выравнивание объекта, т.е 29 бит - теперь же eden нам оставил всего 22 бита - т.е около 4 млн.
 Поскольку мы имеем дело с адресами, и созданием объектов, то нам надо рассматривать очень внимательно и вопрос выделения памяти

# Упрощённый memory allocation

Каждый раз, когда вы создаёте новый объект вы фактически резервируете некоторый объём памяти. И задачей выделения и резервирования памяти занимается аллокатор - простейший случай выглядит так - считаем, что адреса начинаются от 0 и до memoryPointer уже заняты - если мы хотим попросить ещё немного памяти - то сдвигаем границу memoryPointer и так мы зарезервировали объем памяти от старой границы размером size.

Хорош ли такой malloc - что вообще не так с ним ? Есть ли критические замечания ?

# SyncAllocator
Да, предыдущая версия совсем не годилась для работы с многопоточностью и synchronized безусловно теперь её гарантирует.

И логично посмотреть как себя ведёт данный allocator

# SyncAllocator Performance Benchmark

измерить его производительность - скажем на 10 потоках - в реальных приложениях их намного больше

и здесь и далее я буду использовать jmh для измерения производительности, надеюсь, что все знают jmh ? или хотя бы слышали ?

поднимите руки, если в зале кто-то не знает или не слышал о jmh ? (я не шучу)

(очень хорошо - все или почте все знают)

и так - результаты - и здесь, и далее я буду использовать схожие графики для сравнения производительности - единица измерения нс на операцию - чем меньше нс тратится на операцию, тем быстрее, и значит лучше.

при 10 параллельных нитях - почти 400нс на одну аллокацию - это очень дорогая аллокация - для сравнения single-threaded allocator, который применим только к однопоточному случаю, почти в 100 раз дешевле - это будет наш ориентир

# Можно ли лучше ?

Можно ли лучше ? Есть какие-нибудь идеи ?

(CAS?)

Кто-нибудь слышал про Compare-and-Swap ? CAS это операция атомарного сравнения-и-изменения значения, которая реализованая на многих железных архитектурах

# CAS Allocator
Так давайте же сделаем allocator на основе CAS - AtomicLong как раз представляет обёртку вокруг cas для операций с long.

и как всегда померяем - стало ли лучше ?

# Allocators Performance Benchmark
Так же 10 нитей - стало лучше, но не сильно лучше - 245 нс на операцию очень дорого - мы всё так же далеки от идеала

# Можно ли ещё лучше ?

Определённо хочется ещё лучше

# До первой крови

Вернёмся немного обратно к исследованию с помощью коллизий hashCode - как стало ясно из демо про Драку за HashCode - коллизии вызваны размером eden - теперь же давайте соорудим схожее демо, работающее в нескольких нитях - несколько нагнетателей драки - и будем работать до первой драки, т.е до первой коллизии - не важно, в каком бы из нагнетателей она бы не произошла. Более того мы будем делать каждый следующий шаг почти синхронно с другими нагнетателями - в этом нам поможет Phaser - он же Этапщик - одна из реализаций шаблона синхронизации Барьер.

дабы избежать всякие паразитные аллокации - мы заранее преаллоцируем место для объектов - исходя из более ранее опыта - и не будем бросать исключения, будем просто честно записывать состояние распределения адресов каждый шаг - и как только случится драка - тут же прекратим работу - и уже после этого посмотрим где и как они произошли.

Но, потенциально может и OOM произойти - кто за OOM ? Теперь более щипетильный вопрос - а как будут распределены адреса ? Мы же ожидаем, что eden равномерно делится несколькими нитями - каждый шаг мы создаём по одному объекту - а этапщик даёт нам ту самую гарантию, что ни одна нить не убежит вперёд других, больше, чем на один наг.

Кто за то, что разница будет 16 байт (или быть может +- 1 объект) ? Может есть кто не согласен и увидим другое ?

(показываем код **ThreadedIdentityHashCodeCollision** - несколько различий между слайдом - количество потоков получаю как аргумент для запуска приложения - запускаем демо **ThreadedIdentityHashCodeCollision 4** на 4х нитях - и чтобы была многопоточность, и чтобы для демо не слишком много)

Как и ожидали - случились коллизии, а не OOM - и даже суммарно порядок совпадает

# Распределение hashCode по нитям - код

Вот чего не ожидали, так это такой большой разницы... почему ?

Это же подсказка нам - для аллокатора !

# Даёшь БОЛЬШИЕ куски памяти !
Так давайте же напилим такой аллокатор, который будет резервировать память большими кусками синхронно, а внутри потока он будет работать как старый добрый простейший однопоточный.

Да код не такой уж читаемый - SIZE - это размер большого куска - для примера 1Мб - memoryPointer такой же как и в cas-allocator - граница занятой памяти, которую будем менять с помощью cas'а - а в threadLocal у нас будет лежать объект, хранящий значения об использованной памяти внутри нити.

и снова померяем - стало ли лучше ?

# Allocators Performance Benchmark

Круто - вот это уже выглядит намного лучше. Опять же все в 10 нитях, кроме single-threaded.

# Thread Local Allocation Buffer

Собственно подобным образом и ведёт себя аллокатор в java, используя Thread Local Allocation Buffer - каждая нить запрашивает кусок памяти из общей кучи, и внутри своей нити уже выдаёт без каких-либо блокировок - маленькая проверка - не вышли ли мы за пределы зарезервированного объёма.

# Thread Local Allocation Buffer
Когда один TLAB заполнен - запрашивается другой кусок - через блокировки - может быть чуть большего размера

# TLAB и GC
В то время как GC может уже работать в старом TLAB и решать, что делать с объектами - убивать или перемещать их в другое место.

# И снова TLAB
После чего старый кусок памяти снова доступен в eden для того, чтобы его использовал какой-нибудь TLAB.

# До первой крови БЕЗ TLAB

И теперь запустим то же демо **ThreadedIdentityHashCodeCollision 4 -TLAB**, и снова жанглируя с флажками JVM - на этот раз отключив TLAB

# Распределение hashCode по нагнетателям БЕЗ TLAB

Теперь видно, что разница ровно 16 - т.е равна ровно размеру объекта - по сути мы находимся в режиме синхронизированного аллокатора, который на каждую аллокацию выделяет из кучи ровно столько байт, сколько необходимо для объекта.

# Стоимость TLAB
И как всегда померяем насколько эффективно использование TLAB.

# Стоимость TLAB - результаты
Так же, как и моделируемом аллокаторе я использовал 10 нитей - и заметно насколько аллокакция с TLAB лучше, чем без неё - почти в 100 раз

# Распределение адресов
Итак, использование GC и идеи поколений, быстрой аллокации и TLAB приводят к тому, что hashCode из 32х бит потерял почти половину. Коллизии начинают встречаться уже через какие-то полтора-два миллиона новых объектов, после чего все значения строго повторяются.

Мы сами загнали себя в угол с идей использовать адрес в качестве hashcode объекта.

# Может быть Random ?
Может быть ну его нафиг и взять какой-нибудь генератор случайных чисел ?

Что будет с коллизиями в этом случае ?

Вообще насколько должна быть большой набор ключей, чтобы хотя бы у двух каких-либо ключей совпал hashcode ?

Зал, есть идеи ? Нет, ну это очевидно, когда у нас будет 4 млрд значений - то со 100% вероятностью, что хотя бы одна коллизия да будет.

# Парадокс дней рождений
Ответ даёт нам парадокс дней рождений - в группе уже из 23х человек, с вероятностью 50% др совпадут у двух человек. Используя общую формулу мы получим дикие числа - особенно 2^32 факториал - конечно, вольфрам альфа это могут посчитать, но существует формула приближения

так, что не мучаемся - подставляем и считаем - на удивление это всего лишь 77 тыс.
Т.е, если у нас есть 77 тыс ключей, то с вероятностью 50% у двух ключей совпадут hashcode - но не как в случае с адресом, когда значения начнут после некоторого порога строго повторяться.

# -XX:hashCode

Дамы и Господа, Ladies and Gentelmen - это была ловкость рук и никакого мошенничества - умелое жонглирование с параметрами виртуальной машины!

По-умолчанию hashcode в java это всё-таки просто случайное число и все предыдущие демо были проведены с режимом, когда hashcode вычисляется на основании текущего адреса объекта для того, чтобы показать насколько абсурдна эта идея и что есть много других, более серьёзных и важных задач в архитектуре, чем увязывать hashcode и адрес

Этим флагом можно переключать vm в разные режимы генерации hashcode - раньше, до 8ки, по-умолчанию эта был 0ой режим - использоваться генератор псевдослучайный чисел Парк-Миллера, а начиная с 8ки используется 5ый режим - генератор псевдослучайных чисел Марсальи.

С режимом №4 - т.е генерация на основании адреса мы уже все ознакомились, 1ый режим по своей сути ничем принципиально не отличается от генерации на основании адреса. И режим №2, который возвращает всегда единицу - хорошее испытание для работы алгоритма по разрешению коллизий.

# Дамп объекта при -XX:hashCode=5
В доказательство можно посмотреть дамп памяти объекта при флаге по-умолчанию, т.е hashCode = 5. Да, хэшкод хранится всё так же хранится в заголовке объекта, но с адресом никак не связан.

# Распределение hashCode
Для наглядности сравним гистограму распределения hashcode - по адресу - красным, и на основе генератора случайных чисел - синим

Как и ожидали раньше - hashcode от случайного числа равномерно распределен по числовой оси, да есть коллизии - их около 23 тыс (из 10 млн) - т.е 0.23%
И hashcode на основании адреса - в очень узкой полоске, которая соответсвует адресному пространству eden - и количество коллизий чуть больше миллиона

# Beyond the legend

Всё! С мифом о Object.hashcode разобрались - осталось ещё пара тем, касательно hashcode.

# hashCode() и данные

Когда мы создавали телефонную книгу - мы оперировали именами - конечно это мы с вами знаем, что hashcode Баруха +100500, но во всех других случаях он должен быть как-то вычислен - и не важно - получили ли мы это имя по сети, или пользователь ввёл в форму данные, или как-то ещё - ключ один и тот же с точки зрения equals - а следовательно и hashcode должен быть один и тот же.

Т.е, что строки Барух, что экземпляры 42 - каждый из них имеет один и тот же hashcode соответственно.

Как же он вычисляется ?

# простой hashCode

В качестве простого примера рассмотрим точку - у которой есть два свойства - x и y - и тогда hashcode будет как сумма этих координат с разным весом.

У Джошуа Блоха в его книге Effective Java этому посвящёна отдельная глава - основная идея использовать простые числа в качестве множителей, опять же в угоду минимизации коллизий - и с другой стороны мы хотим, чтобы метод был относительно простой и не требовал много ресурсов на вычисление.

Как правило, подобный подход нацелен на общий случай - решает усреднённую задачу, для большинства случаев - однако, если у вас узко специализированная задача и вы знаете диапозон допустимых значений - то можно подобрать другие коэффециенты дабы минимизировать коллизии.

Например, если вы работаете в квадрате 100 на 100 - то почему бы не выбрать множитель больше 100 и посмотреть распределение коллизий для известного набора данных.

И конечно же не забывайте переопределять метод equals, который должен быть согласован с hashcode

# Objects.hash
И начиная с 7ки - hashCode можно вычислить просто передав свойства в utility method - и все вычисления для средне-хорошего случая будут проведены внутри.

В общем случае это будет полиминальная функция от количества аргументов.

# Полиномиальный hashCode

И как раз одну из типичных реализаций hashCode можно увидеть в строке - складываем все элементы массива с весами по степеням 31.

Но почему именно 31 ? Не 2, не 5, а именно 31 ? Есть идеи ?

# Почему 31 ?

Во-первых всеми известный Дональд Кнут в третьем томе "искусства программирования" обосновывает использование полиминальной функции для вычисления hashcode - и в качестве коэффециентов использует простые числа.

Однако в самых первых версиях java hashcode для строки вычислялся архаичным способом - для строк меньше 16 символов это был полином с коэффециентом 37, а если строка длинее - то вычислялся фактически для части подстроки.

И один из отцов Java - небезызвестный Джошуа Блох решил это исправить - в книге Kernighan и Ritchie - Язык программирования Си - был дан готовый рецепт - и без доказательно даётся число 31 - тогда Джошуа связался с Брайном Керниганом - но тот забыл уже откуда он взял это число - просто оно работает.

И тогда Блох провёл небольшое исследование - взял слова и словоформы из словаря Merriam-Webster - что дало ему около 300 тыс строк, все строки в солярисе в /bin/*, /usr/bin/* и т.д - это дало ему ещё 66 тыс строк - и !!! он запустил веб-паука, который за несколько часов собрал ему около 30 тыс урлов - сейчас это выглядит более, чем забавно - но 20 лет назад таков был интернет.

И вот он собрал все эти строки и проанализировал уровень коллизий - та, реализация, которая была на тот момент давала очень высокий уровень коллизий, а уровень коллизий при коэффециентах 31, 33 и 37 оказался примерно одинаковый. + 31 достаточно близко к 32, так, что многие компиляторы могут представить умножение 31 как сдвиг и вычитание.

Кстати, уже тогда вопрос об обратной совместимости в java стоял жёстко - но всё же решили её сломать для эффективности.

Словом - в результате было выбрано число 31 - как и у Kernighan и Ritchie. В чём-то это Ответ на главный вопрос жизни, вселенной и всего такого в java.

# Но ведь можно подобрать…

Но ведь далеко не все строки осмысленные слова - можно же подобрать такие значения, которые будут давать один и тот же hashcode - это - один самых известных примеров.

И так, зная он как вычисляется - можно найти такие строки, которые будут иметь один и тот же hash code.

Возьмём два рядом стоящих символа в строке - если уменьшаем левый на единицу, то правый - надо умеличить на 31. Или наоборот, если левый увеличиваем на 1 - то правый уменьшаем на 31. Подобный приём можно применить для двух символов, между которыми находится ещё один, и т.д. Проще всего искать строки такой же длины - отталкиваясь от уже существующей строки - хотя конечно можно искать и варианты с бОльшей длиной строки - играя на переполнении целого числа.

Для примера я взял строку "username" и направленным поиском - меняя соседние символы - нашёл почти полмиллиона вариантов.

Думаю, что понятно, что чем длинее строка, тем больше можно найти или подобрать вариантов коллизий, в то время, когда если строка состоит только из одного символа - например q - то там труднее развернутся - только искать строки бОльшей длины.

# "username" коллизии :: benchmark

И давайте сделаем такой benchmark - здесь опущен setup метод для краткости - он загружает из файла заданное количество строк с коллизями, проверяет, что hashcode загруженной строки равен hashcode "username".

а сам benchmark - это добавить эти ключи в hashmap, собственно эта проблема была описана в приведённой баге, хотя её зарепортили ещё в 2011.

Так и что же у нас получается ?

# "username" коллизии :: java7 результаты

легко можно заметить параболу на графике - т.е квадратичная сложность - если честно - я не ожидал увидеть время отклика 1.5 минуты, передавая 200 тыс ключей.

Откуда пробелема возникла, думаю уже понятно - почти в самом начале я рассказывал про коллизию Баруха и других ведуших Разбора Полётов - и для разрешения коллизий использовали подход, который называется chaining - по своей сути это просто linked list.

Если посмотреть как обрабатываются cookies, или параметры http-запроса в Tomcat'е - то там используется как раз LinkedHashMap - но для случая вставки ключей это ничем не лучше обычного HashMap. А после того, как все ключи из запроса будут загружены в map - приложение, или сервлет ищет нужный ему параметр - собственно поэтому я и выбрал в качестве ключа "username" - достаточно часто используемое имя параметра. А поиск ключа в мапе, в которой его нет, но есть много коллизий - заставит перебрать все ключи с одинаковым hashcode - а это ещё немного усугубит проблему.

И во время измерений я смотрел за загрузкой cpu - и на все эти 1.5 минуты одно ядро было загружено под 100% - доклад и конференция не про DOS-атаки, но идея думаю более, чем ясна.

И как всегда - главный вопрос - Что делать ? Кто нам поможет ?

# 23derevo

Нет, это не Чип, и не Дейл - это - Алексей Фёдоров - 2-3-дерево, надеюсь, что все узнали ?
В отличии от Кашпировского - java чемпион устраняет проблемы не взглядом , а своим добрым именем.

дело в том, что 2-3-дерево - как структура данных - изоморфна по своим свойствам красно-чёрному дереву. Минута занудства - 2-3 дерево - такое Б-дерево, у которого либо 2, либо 3 дочерних элемента, а красно-чёрное дерево это бинарное дерево поиска, в котором баланс осуществляется на основе "цвета" узла дерева. т.е цвет элемента в красно-чёрном дереве можно преставить как третий дочерний элемент у 2-3-дерева.

# Бинарное дерево поиска

для нас важно то, что красно-чёрное дерево является

бинарным деревом поиска,
самобалансированным два,
и относительно простым в реализации - три

всё это в итоге даёт нам структуру данных с логарифической сложностью как на операциях поиска, так и вставки и удаления.

И тогда мы будем разрешать коллизии с помощью такого гибрида из hash структуры и бинарного дерева поиска - в java начиная с 8ки внутри HashMap, LinkedHashMap, ConcurrentHashMap используется красно-чёрное дерево

# "username" коллизии :: map.put(key, key)

И вот как выглядит сравнение того же самого теста с коллизями по username в 7ке и в 8ке - вот тот график, который слабо отличается от нуля - это 8ка - ибо там совершенно другой масштаб времени - положить все 200 тыс ключей на 8ке занимает где-то 100 мс

Кто ещё свои приложения в проде держит на 7ке ?  или на 6ке ?)

# "username" коллизии :: zoom-in 500x

если изменить масштаб в 500 раз - обратите внимание на шкалу времени - на это графике это миллисекунды - отклик 8ки почти линеен, а 7ка сразу ушла в небеса - точка возле 200 мс это при 1000 ключей

# "username" коллизии :: java8

И вот результаты работы тех же 200 тыс коллизий на 8ке в пересчёте на одну вставку - поведение графика чётко указывает на логарифическую сложность - типичная сложность древовидных структур

# String join

И пожалуй последняя тема, которая на первый взгляд никак не связана с hashcode.

Думаю всем когда-то приходилось склеивать строки и писать что-то подобное, не так ли ?

# StringBufferPerfTest

И давайте напилим такой вот бенчмарк

Два разных буфура, добавляем одну букву, и получаем строку.

Да, и второго буфера ещё вызовем System.identityHashCode - но это только в setup методе, т.е один раз перед всеми измерениями, даже ещё до разогрева.

Это всё в одной нитке - Какие будут ожидания ? Кто быстрее ? +- одинаково, не так ли ?

# StringBufferPerfTest результаты

Неожиданно ? Опять какая-то магия и мистификация ?

# Biased Locking

Не редко бывает так, что объект является thread-safe, но по факту он используется почти всегда одной нитью, и очень редко когда какая-то другая нить захватыает его монитор.

У StringBuffer все методы синхронизированы - и наш тест работает в одном потоке - т.е это именно наш случай.

Захват от отпускание монитора это не дешевые операции - поэтому изыскиваются возможности как облегчить. А что если не сделать так - если монитор уже был захвачем данной нитью - то как-то его пометить, привязать к этой нитке, а потом просто проверять чем-то более дешевым типа CAS. Это и есть основная идея Biased locking.

Вопрос в том где размещать эту метку нити ? И как всегда нам поможет JOL

# Biased Locking demo

И так - создаём объект и снимаем его дамп - в нулевой момент времени в заголовке объекта вообще ничего нет

# Biased Locking demo 2

После того как мы захватываем монитор объекта в заголовок объекта записывается id нити - id нити можно получить, например, используя thread dump или инструментами типа jvisualvm

# Biased Locking demo 3

И стоит нам позвать System.identityHashCode - как он отозвёт biased locking и запишет себя в заголовок объекта - и так же поменяет флаг в первом байте - который как раз и говорит - что теперь это объект с системным hashcode - после это biased locking больше уже не работает для данного объекта.

И в таком случае захват монитора снова становится дорогим.

# Заключение

И капитанство в заключении -

Hash структуры данных это одни из быстрых структур данных,
Используя свои собственные ключи - не забывайте переоределять не только hashcode и equals, но и реализуйте интерфейс Comparable - это защитит вас в случае средне-плохого универсального способа вычисления hashcode - новой редакции Effective Java пока ещё нет, но я больше, чем уверен - это будет там. Хотите, чтобы было ещё лучше и меньше коллизий - исследуйте свои hash-функции не только на предмет абсолютных коллизий, но и на предмет коллизий после мастшабирования на размеры массива - это может сократить расход памяти.

И просто жанглируя флагами vm из протёкшей абстракции Object.HashCode можно увидеть уши нескольких отличных инженерных решений в архитектуре - это и копирующий GC, и быстрые аллокации, и облегчённый завхат монитора, но не злоупотербляйте System.identityHashCode.

И уж точно можно сказать - hashcode это не адрес объекта. По крайней мере, по-умолчанию.

# Контакты

Все демо и слайды доступны на github-е

Спасибо.

