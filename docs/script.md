*2017-04-02*

# preparation
* Idea
    * default (белая) тема
    * отключить show whitespaces
    * presentation mode
* MacOsX settings
    * Dock - automatically hide and show Dock
* Выключить все IM!

# Внутрь VM сквозь замочную скважину hashCode
Меня зовут Владимир и мы будем сквозь замочную скважину заглядывать внутрь VM java. Более точнее - OpenJDK и OracleJDK, как самые доступные и самые распострённые реализации java vm.

# no warranty

всё, что вы здесь услышите - это моя личная точка зрения, которая может быть ошибочна.

# план
* в начале вспомним теорию, а именно ассоциативные массивы и как они устроены.
* расскажу о классическом способе вычисления hashcode - при этом я не буду рассказывать про другие hash-функции такие как MD5 или SHA1
* и как можно используя знания о том как вычисляется hashcode устроить DoS атаку, и как вылечить её
* и затем окунёмся в детали виртуальной машины - разрушим старый миф, будут и потроха - сборщик мусора, и аллокация, и немного баттлов - конечно же при этом мне нужны будут ваши голоса - не стесняйтесь поднимать руки
* и на последок ещё один трюк виртуальной машины и как hashcode может всё изменить

# Ассоциативный массив / Dictionary / Map
ассоциативный массив - что это такое  ? это структура данных, позволяющая хранить пары ключ-значение и поддерживающий операции вставки, поиска и удаления по ключу.

Как он устроен внутри ? Как правило ассоциативный массив реализуется как два массива - один для ключей, другой для значения. например, у нас есть телефонная книга - ключом будет выступать имя, а значением будет его номер телефона.

Идея заключается в том, что используя hash-функцию можно отобразить ключ на число - и вычистлить индекс в массиве, куда записать ключ и соответственно значение.

важный момент - поскольку число может быть любым - т.е как очень большим - так и отрицательным, а доступная память ограничена - поэтому полученное число предстоит ещё отмасштабировать на длину массива - например, можно использовать остаток от деления на длину массива.

# javadoc
За hash-функцией далеко ходить не надо - у java.lang.Object - корневого класса всей иерархии классов в java - определен метод hashcode - т.е по сути каждый объект в java обладают некоторой стандартной hash-функцией.

Так же обратим внимание, что hashcode возвращает int - это знаковое 32х битное целое число.

# Записать ( Алексей, +791… )

рассмотрим поясняющий пример - допустим уже записано несколько адресатов и надо записать Алексея - и его телефонный номер. Предположим, что его hashcode равен 23 - для пояснения работы это не принципиально, но о том как именно вычисляется hashcode мы обязательно вернёмся позже.

И так - вычисляем индекс в массиве и записываем значение.

# сложность

алгоритм поиска выглядит примерно так же - вычисляем hashcode, мастшабируем и проверяем ключ, что записанный ключ равен искомому.

т.е вставка, поиск никак не зависят от длины массива - сложность константа.

это самое главное свойство ассоцитивного массива.

# Контракт hashCode

одно из ключевых свойств hashcode - это не изменчивость и постоянство - и опредён контракт для hashcode -  этот метод должен постоянно возвращать одно и то же значение.

# Нарушение контракта hashCode

если бы не было бы этого контракта - и hashCode мог меняться - например, для Алексея он стал бы отличным от того, что было когда записали ключ-значение - то мы уже не найдём его.

# Коллизии

и ложка дёгтя - что, если нам предстоит записать Alexander, Alex и Jan - и, предположим, что у всех такой же hashcode, как и у Алексея.

Совпадение hashcode ключей - это коллизия, и её придётся как-то разрешать - ситуация не приятная, но типичная.

Надо сказать, что коллизии это самая большая проблема в хэш-структурах - используют и разные подходы для разрешия коллизий, и чтобы их не допустить - стараются найти хэш-функцию получше, но для общего случая её сложно подобрать.

# Chaining

И т.к такой идеальной функции нет - то используют то, что есть - а есть то, что либо вернул метод hashCode() - и что там пользователь напишет - может быть ужас-ужас.
Существует несколько широкораспостраннёных способов разрешать коллизии - и chaining один из них. По сути надо список и поместить все ключи с одинаковыми hashcode в него. способ универсальный, но далек от идеала, и как плата за это - сложность поиска становится линейной.

# Открытая адресация

другая вариация представления списка используется в другом способе разрешения коллизий, которая называется открытая адресация - заключается в том, что исходный массив ключей используется как список и в нём делается последовательность проб относительно исходного индекса - если ячейка занята - делают следующую пробу - например, выбирают соседнюю ячейку - например, всё время идти влево.

# Открытая адресация (сложность)

если же и она занята - делают ещё пробу и так до тех пор пока не будет найдена свободная ячейка.

очевидный плюс - не нужна дополнительная структура данных и компактное размещение данных.

но и в этом случае сложность деградирует до линейной.

Это очень важный момент - коллизии способны сломать производительность, и чем больше коллизий, тем только хуже операции типа поиска, вставки и т.п

# hashCode = функция ( содержимое объекта )

Как же вычисляется hashCode ? как правило hash-функция это некоторая функция над содержимым объекта.

И хорошо бы знать, как он должен быть как-то вычислен - ведь не важно - получили ли мы строку по сети, или пользователь ввёл в форму данные, или как-то ещё - ключ один и тот же с точки зрения содержимого - т.е они равны с точки зрения equals - а следовательно и hashcode должен быть один и тот же.

Т.е, что строки java, что экземпляры 42 - каждый из них имеет один и тот же hashcode соответственно.

Вообще, строго говоря - в качестве hashcode может быть всё, что угодно - хотите возвращайте константу, но тогда можно забыть об быстром доступе по ключу. Т.е. чем лучше будет hash-функция и чем меньше будет коллизий - тем будет лучше.

# Полиномиальный hashCode

У Джошуа Блоха в его книге Effective Java вычислению hashcode посвящёна отдельная глава -

Традиционно для общего случая рекомендуется использовать полином по свойствам класса с простыми весами, например 31 - простые числа выбираются опять же в угоду минимизации коллизий - и с другой стороны мы хотим, чтобы метод был относительно простой и не требовал много ресурсов на вычисление.

Как правило, общий случай решает усреднённую задачу, для большинства случаев - однако, если у вас узко специализированная задача и вы знаете диапозон допустимых значений - то можно подобрать другие коэффециенты дабы минимизировать коллизии.

# String.hashCode()

И как раз одну из типичных полиминальных реализаций hashCode -  можно увидеть в строке - складываем все элементы массива с весами по степеням 31.

так же иногда применяют lazy вычисление и кэширирование уже вычисленного значения.

# String.hashCode() javadoc
Да - и более того - этот алгоритм вычисления так же прописан в javadoc к этому методу - и это значит, что это часть публичного API и все сертифицированые реализации JVM обязаны быть полином с весом 31.

Но почему именно 31 ? Не 2, не 5, а именно 31 ? Есть идеи ?

# java v.1.1.1 - String.hashCode()

в самых первых версиях java hashcode для строки вычислялся архаичным способом - здесь и разные коэффециенты при разных длиннах строк, и пропуск отдельных символов - жуть

И тот же Джошуа Блох решил это исправить

# 31 : Детективная история

Есть такой вот замечательный баг - который как раз посвящён исправлению архичному вычислению hashcode

- в книге Kernighan и Ritchie - Язык программирования Си - был дан готовый рецепт - и без доказательно даётся полиминальная функция с числом 31 - тогда Джошуа связался с Брайном Керниганом - но тот забыл уже откуда он взял это число - просто оно работает.

Блох провёл небольшое исследование - взял слова и словоформы из словаря Merriam-Webster, все строки в солярисе в /bin/*, /usr/bin/* и т.д - и на последок он запустил веб-паука, который за несколько часов собрал ему около 30 тыс урлов - сейчас это выглядит более, чем забавно - но 20 лет назад таков был интернет.

И вот он собрал все эти строки и проанализировал уровень коллизий - та, реализация, которая была на тот момент давала очень высокий уровень коллизий, а уровень коллизий при коэффециентах 31, 33 и 37 оказался примерно одинаковый. + 31 достаточно близко к 32, так, что многие компиляторы могут представить умножение 31 как сдвиг и вычитание.

Словом - в результате было выбрано число 31 - как и у Kernighan и Ritchie. В чём-то это Ответ на главный вопрос жизни, вселенной и всего такого в java.

# Но ведь можно подобрать…

Но ведь далеко не все строки это осмысленные слова - можно же подобрать такие значения, зная как вычисляется hashcode , которые будут иметь один и тот же hash code.

строки Аа и ББ - один самых известных примеров

Возьмём два рядом стоящих символа в строке - если уменьшаем левый на 1, то правый - надо увеличить на 31.
Или наоборот, если левый увеличиваем на 1 - то правый уменьшаем на 31.

Подобный приём можно применить для двух символов, между которыми находится ещё один, и т.д. Проще всего искать строки такой же длины - отталкиваясь от уже существующей строки - хотя конечно можно искать и варианты с бОльшей длиной строки - играя на переполнении целого числа.

Для примера я взял строку "username" и направленным поиском - меняя соседние символы - нашёл почти полмиллиона вариантов. Хотя даже этого оказалось много.

и давайте измеряем влияние коллизий.

и здесь и далее я буду использовать jmh для измерения производительности

# Java Microbenchmark Harness

* поднимите руки, если в зале кто-то не знает или не слышал о jmh ?
* а теперь, кто что-то хотя бы слышал о нём.
* и кто его и знает, и использует или иногда использует.

Если кто не знает - буквально кратко - что это и зачем - написать бенчмарк не составляет особого труда, но написать корректный бенчмарк, который будет действительно правильно измерять и измерять именно то, что хочется - это значительно сложнее.

и jmh это фреймфорк по написанию правильных nano/micro/milli performance benchmarks для java. он составляет часть openjdk toolset и так же люди из openjdk его поддерживают и развивают.

# JMH :: "username" коллизии :: benchmark (1)

Поскольку мы будем не один раз прибегать к использованию JMH - давайте я на конкеретном примере покажу, что и как можно получить используя jmh.
Примерно вот так или подобно так выглядит benchmark - у нас есть само тело бенчмарка - измеряем как быстро мы можем добавить все ключи в map'у

# JMH :: "username" коллизии :: benchmark (2)
можно указывать как долго надо разогревать VM, дабы исключить краевые эффекты связанные с jit компиляцией, прогревом vm и не только, можно указывать как долго надо измерять сам бенчмарк, чтобы получить статистически корректные измерения, можно специфицировать в скольких нитях будет работать бенчмарк,

# JMH :: "username" коллизии :: benchmark (3)
по аналогии с junit можно специфицировать setup и teardown методы, которые соот-но вываваются перед и после работы тела бенчмарка - именно там я загружаю из файла найденные коллизии для строки username - всё это вспомогательные операции для самого бенчмарка. и так же по аналогии с junit можно параметризовать benchmark - я хочу проследить за производительностью при разном количестве коллизий.

конечно - это не избавляет от того, чтобы писать неправильные benchmark-и и/или неправильно их трактовать - если ещё не делали - смотрите записи Алексея Шипилёва, где он подробно расскаывает о jmh, на сайте проекта есть подробные примеры.

словом - jmh - важный и полезный инструмент в руках инженера.

и давайте уже посмотрим, что у нас получается ?

# "username" коллизии :: java7 результаты

Кстати, кто ещё свои приложения в проде держит на 7ке ?  или на 6ке ?)

легко можно заметить параболу на графике - т.е у нас квадратичная сложность - если честно - я не ожидал увидеть время отклика 1.5 минуты, передавая 200 тыс ключей.

Откуда пробелема возникла, думаю уже понятно - почти в самом начале я рассказывал про коллизии - и для их разрешения использовали chaining - по своей сути это просто linked list.

Если посмотреть как обрабатываются cookies, или параметры http-запроса в Tomcat'е - то там используется как раз LinkedHashMap - но для случая вставки ключей это ничем не лучше обычного HashMap. А после того, как все ключи из запроса будут загружены в map - приложение, или сервлет ищет нужный ему параметр - собственно поэтому я и выбрал в качестве ключа "username" - достаточно часто используемое имя параметра. А поиск ключа в мапе, в которой его нет, но есть много коллизий - заставит перебрать все ключи с одинаковым hashcode - а это ещё немного усугубит проблему.

И во время измерений я смотрел за загрузкой cpu - и на все эти 1.5 минуты одно ядро было загружено под 100% - доклад и конференция не про DOS-атаки, но идея думаю более, чем ясна.

Что нам делать ?

# ещё одна функция нужна

Нужно выйти за рамки существующих возможностей - одна из вариаций разрешения коллизий в открытой адресации заключется в использовании двойного хэширования.

Может быть вы слышали, что не так давно в SHA1 нашли коллизии - с очень маленькой вероятностью, но всё ненулевая вероятность, у MD5 вероятность коллизий выше - но поскольку базис данных hash-функций разный - то и результирующая вероятность коллизии почти, что нулевая.

Идея заключается в том, что взять ещё одну функцию - желательно, ортогональной исходной - как это, например, может быть вторая hash-функция, либо вообще функция из другой области и рассматривать её как обобшённую вторую функцю для разрешения коллизий

# Дополнительная функция: compareTo

И что у нас уже есть в стандартной библиотеке ? строки, и числа, даты и многие другие классы - все они сравниваемые - т.е у них реализована функция compareTo. Её мы и будем использовать как вторую функцию для разрешения коллизий.

тогда для разрешения коллизий можно строить бинарное дерево поиска, которое обладает логарифической сложностью.

В java начиная с 8ки - внутри HashMap, LinkedHashMap, ConcurrentHashMap используется красно-чёрное дерево для разрешения коллизияй при привышении некоторого порогового числа коллизий

# Chaining и Красно-Чёрное-Дерево

пока уровень коллизий мал, а именно меньше 8 элементов, то там по прежнему chaining.

Если у вас есть сомнения относительно коллизий в вашем приложении - самый простой способ их оценить - это снять heapdump и посмотреть количество экземпляров TreeNode - они появляются тогда, когда уровень коллизий больше 8, если у вас одни Node - значит уровень коллизий мал и беспокоится особо не стоит.

давайте же посмотрим на результаты работы данного подхода.

# "username" коллизии :: map.put(key, key)

так выглядит сравнение того же самого теста с коллизиями по username в 7ке и в 8ке - вот тот график, который слабо отличается от нуля - это 8ка - ибо там совершенно другой масштаб времени - положить все 200 тыс ключей на 8ке занимает где-то 100 мс

основной эффект прежде всего из-за изменения внутренней реализации hashmap - если сделать backport hashmap из 8ки в 7ку - то цифры будут схожими с теми, что мы видим для 8ки.

# "username" коллизии :: 500x zoom-in

если изменить масштаб в 500 раз - обратите внимание на шкалу времени - это миллисекунды - 7ка сразу ушла в небеса - точка возле 200 мс это при 1000 ключей - а 8ка кажется, что почти линейна, хотя это конечно же не так

# "username" коллизии :: java8

только же результат, но в пересчёте на одну вставку - хорошо заметен логарифм - типичная сложность древовидных структур

# "username" коллизии :: Comparable

Одно очень важное замечание - для того, чтобы строить деревья - ключи обязаны быть сравниваемыми - строки, числа, даты и многие другие объекты как раз сравниваемые - т.е реализовывать интерфейс Comparable, но если он не сравниваемый - то нас ждёт ещё более худшая ситуация.

Для сравнения я реализовал тот же бенчмарк, но в качестве ключа я использовал не java.lang.String, а класс-обёртку, но который НЕ реализует интерфейс Comparable.

И всё тот же набор ключей, полученный из коллизий по строке username.

проблема заключена в том, что дорого обходится попытка внести упорядочивание в естественно неупорядоченные ключи

Т.е. если вы каким-то образом получаете данные из не надёжного источника - н-р внешняя сеть - и по каким-то причинам используете свои классы в качестве ключей - например, пары или кортежи в качестве ключей - стоит рассмотреть возможность реализации Comparable - хотя не всегда это может быть и естественный порядок.

# утёкшая абстракция

Как вычислять hashcode у которого нет данных ? hashcode определён у java.lang.Object - значит все классы, которые не переопределяют этот метод - ведут себя точно так же. И что же собственно он возвращает ?

Вообще это очень странно, когда корневой класс иерархии содержит в себе метод ради реализации ассоцитивного массива.
Например, существует интерфейс Comparable для сравнения объектов, но нет интерфейса Hashable.

Надо сказать, что наличие этого метода у Object с реализацией по-умолчанию повлекло за собой последствия, из-за которых мы можем заглянуть в дебри виртуальной машины исследуя его.

# Urban Legend

Более того - это даже породило легенду, которая гласит, что hashcode это адрес объекта - т.е если записать hashcode что-то в виде Cи-кода

# Urban Legend: Первоисточник

Первоисточником легенды является всё тот же javadoc к которому мы уже не раз обращались - и в нём сказано, что типичная реализация метода hashcode у java.lang.Object это преобразование внутреннего адреса объекта к числу.

Попробуем не только разрушить этот миф, но и наглядно показать, почему это не самый лучший выбор.

И так - предположим, что hashcode объекта это всё таки его адрес. В качестве инструмента будем использовать конечно же сам hashcode - и его свойства - неизменчивость и распределение значений. Будем проверять разные предположения на корректность при помощи тестов.

# Адрес объекта

вообще, первое, что приходит на ум, когда слышишь утверждение "hashcode использует адрес объекта" - это взять и проверить.

Но как надёжно получить адрес объекта ? Мало того, что в java отстутсвует арифметика указателей на уровне языка - как, например, в Си, так ещё и hashcode это только 32 бита, а адрес объекта в современном мире 64х битных платформ - может быть запросто быть больше 32х бит.

# native method

Если мы посмотрим на исходный java код java.lang.Object - то увидим, что этот метод является native - т.е он реализован на уровне самой VM.

# Шипилёв-слайд

Кто любит unsafe ?

SHORT VERSION:
* Конечно же можно при помощи unsafe получить адрес объекта - но подводных камней очень много - и то, что нельзя его создать через оператор new - обычно воруют экземпляр через reflection, и что в самом unsafe нет метода по получению адреса объекта - и в довершение - размер указателя объекта может быть как 32 бита даже на 64х битной java, но может быть и 64 - и в конце концов это приватный API, который должен закрыт. основная причина почему unsafe стал столь популярен - не было альтернатив.

# EXT VERSION: sun.misc.Unsafe

Может быть вы слышали хотя бы краем уха, а может нет - есть такой класс - sun.misc.Unsafe, который даже из названия предполагает, что использовать его не безопасно, так в общем-то оно и предполагось в sun - ибо в java он появился задолго до того, как Oracle поглотила Sun.
Словом, предполагалось, что это будет часть приватного API, только для внутренних нужд jdk, но уж слишком вкусные вещи есть внутри

например - можно выделить или освободить память как в старом добром Си, получение long и не только из объекта по некоторому смещению - и много ещё всякого фарша - но вот такого метода, чтобы получить адрес сразу нет.

# EXT VERSION: Unsafe :: адрес объекта (1)

Как я уже говорил - API приватный и всё, что делаете с ним - это только на ваш страх и риск. Этот объект нельзя просто так создать ни через оператор new - ни вызвав factory-method getInstance - обычно воруют уже существующий экземпляр через reflection.

# EXT VERSION: Unsafe :: адрес объекта (2)
А для того, чтобы получить адрес объекта - Применяется небольшая хитрость - создаём массив - и в него кладём исследуемый объект - и по смещению получаем адрес.

# EXT VERSION: Unsafe :: адрес объекта (3)
В общем-то ничего сложного, если бы не одно существенное но. Данный подход работает тогда, когда 64 бита, сжатие укзателей в java отключено, либо когда размер кучи куда больше 4гб.

и всё как всегда с арифметикой указателей - чуть промазали или не учли какой-то фактор - и сразу же боль.

Понятно, что для наших праздных целей посмотреть-да попробовать ничего страшного не случится, но как инструмент не выглядит надёжно.

# Java Object Layout

EXT VERSION:
 * Нашу боль разделяют и люди в openjdk - и они создали инструмент, который позволяет проводить анализ компоновки объекта - расположение полей, сколько байт занимают - словом всё, что связано с его компоновкой.

SHORT VERSION:
* для задачи проведение анализа компоновки объекта, его адреса, размера, расположение полей, сколько байт занимают - есть альтернатива, созданная людьми из openjdk - Java Object Layout.

И конечно же он сразу же из коробки даёт возможность получить - и адрес объекта, и его размер, можно достаточно просто снять дамп объекта и посмотреть его содержимое - без каких-либо Unsafe и прочей магии с головыми болями - всё это спрятанно как-то там внутри. В конце-концов авторы openjdk лучше знают и об внутреннем устройстве объекта, обо всех краевых случаях.

Словом - давайте забудем про Unsafe и будем использовать JOL.

# JOL : пример

Кто из вас слышал и использовал Java Object Layout ?

И если JMH как инструмент неплохо известен - то о JOL мало кто-то знает - давайте покажу один из примеров использования

пусть у вас есть класс - pair - составной ключ, состоящий из двух ключей,
и вы захотели добавить поле - hashcode - чтобы его закэшировать и не вычислять каждый раз - как это сделано у String, например.

на сколько изменится потребление памяти ?

int же 4 байта ? кто за то, что потребление памяти увеличится на 4 байта на каждый объект Pair2 ? а кто за какое-то другое число ?

# JOL : -XX:+UseCompressedOops

и JOL даёт ответ... ни на сколько не изменится, если у вас меньше 4х гб хипа и включёно сжатие указателей - а оно включёно по-умолчанию.

детализация, которую даёт JOL показывает что это произошло из-за чтого, что есть выравнивание объектов на 8 байт. и когда мы добавили hashcode - мы как раз использовали этот ранее не использованный зазор.

# JOL : -XX:-UseCompressedOops или heap > 4Gb

Но если у вас больше 4х гб или отключено сжатие указателей - объект будет потреблять не на 4 байта больше - а на 8

изменились и размеры указателей, и тоже да из-за выравнивания размеров объекта по 8 байтам - более того - видно, что в свойство hashcode теперь располагается в начале объекта - т.к физическое распложение полей в runtime в java может значительно отличаться от того, что задеркларировано.

вот на все подобные вопросы и поможет ответить JOL.

# Адрес и hashCode

вернёмся же к hashcode - при помощи одного флага VM - мы можем добится того, что наше предположение будет истино.

Наглядней всего заметно сходство, если мы представим всё в 16 системе счисления - hashcode использует младшие 32 бита адреса, тут же и видим размер объекта - 16 байт.

Что же - теперь можно смело исследовать влияние такой реализации hash-функции и что мы можем увидеть через призму этого предположения.

# Следим за адресом объекта (1)

И первый эксперимент - проверить насколько можно доверять адресу объекта - для проверки этой гипотезы давайте создадим новый объект - theObject - в данном демо это будет главная цель нашего наблюдения - зафиксируем адрес этого объекта в самом начале

# Следим за адресом объекта (2)

затем будем создавать другие объекты и, чтобы избежать того, чтобы GC собрал их как мусор - будем хранить их в списке gcKeeper.

# Следим за адресом объекта (3)

Основная цель - следить за адресом объекта theObject - как только адрес изменится (а может он никогда не изменится?) мы выйдем из цикла и прекратим создавать объекты.

# Следим за адресом объекта (4)

В демонстрационных целях - чтобы не ждать OOM долго - я ограничу размер кучи до 256Мб. И использую SerialGC - тот же самый эффект при других сборщиках мусора, возможно с небольшой разницой по цифрам.

Поскольку наши объекты не могут быть собраны - у нас есть все шансы получить OOM, если адрес не поменяется.

И так - голосуем - кто за OOM ? А кто за то, что адрес объекта изменится ?

# demo
(Открываем и показываем **ObjectReallocation** - Запускаем **ObjectReallocation** и смотрим демо.)

Что произошло ??? Почему ?

# GC: поколения

зал - кто не слышал про поколения в сборке мусора ? поднимайте, поднимайте руки) и теперь - кто слышал ?

Давайте бегло объясню общую идею - много лет назад была высказана гипотеза, что большинство объектов короткоживущие - т.е умирают вскоре после того как они были созданы - буквально слоган панков - жить быстро, умереть молодым.
это сделано из тех соображений, чтобы сборщику мусора обходить не весь граф объектов - он обходит только очень малую часть.

Т.е объекты рождаются в eden, если он не умер молодым, то он перемещается в более старшее поколение - survivor, и потом может быть перемещён в старое поколение - old generation, куда сборщик мусора почти заходит очень редко - GC обходит old gen только во время полной сборки - т.е Full GC.

java использует эту гипотезу о поколениях - и в общем-то она не плохо даже работает - но с ростом объёмов памяти и ростом числа объектов гипотеза уже не так удачно работает как раньше - не так давно стали появлятся другие гипотезы - как например региональная гипотеза, которая реализована в G1 и shenandoah.

# Следим за адресом объекта вместе с GC

Давайте добавим дополнительный флаг для запуска VM - а именно будем отслеживать GC и запустим то же самое демо

(Запускаем **ObjectReallocation (gc)** и смотрим демо.)

Теперь видно, что произошла сборка мусора - и более того, по GC логу можно даже понять откуда и куда был перемещён наш объект

# GC - не только сборка мусора

вот лог такого же запуска - объект изначально был создан в eden - и GC переместил его за пределы eden - и именно это мы и заметили.

понимаю, что сравнивать 16тиричные числа как-то не удобно - поэтому я просто расположил адреса налача eden, старый т.е исходный адрес объекта, конец eden и новый адрес объекта в порядке возврастания адресов

т.е. Garbage Collection не просто собирает мусор, но и производит перемещения объектов - это применимо как к сборщикам по поколениям, так и региональным - такие как G1

# Следим за hashcode

Изменение адреса объекта, порождает следующий эксперимент - если может изменится адрес - то возможно может и hashcode изменится - мы же помним, что hashCode это адрес объекта, да ?

По сути делаем всё то же самое, что и в предыдущем эксперименте, только на этот раз будем следить не за адресом объекта, а hashcode - так же зафиксируем начальное значение, и так же будем создавать новые объекты и хранить их в gcKeeper пока не изменится hashcode, либо не случится OOM

И так же как и в предыдущем демо размер кучи уменьшил до 256Мб.

Голосуем - Кто за то, что hashCode изменится ? Прошлый же раз адрес поменялся, а hashcode это же адрес, так ведь ?  А кто за OOM ?

# demo

(показываем код **ObjectHashReallocation** - так же как и в предыдущем демо - отличие от слайда только в сообщении после цикла - Запускаем **ObjectHashReallocation** и смотрим демо.)

Что случилось ? Почему ?

Объект не может нарушать контракта hashcode, hashCode является собтсвенностью объекта, более того - неизменяемой собтсвенностью.

Напрашивается вывод, что данное свойство где-то хранится и оно является

# Скрытое свойство

Скрытым свойством - Как мы помним - hashcode это native метод, но на уровне java кода ни одного свойства у java.lang.Object не определено. И нам надо идти глубже, и поможет нам в этом снова Java Object Layout !

Давайте при помощи JOL сделаем dump объекта - т.е как объект целиком представлен в памяти.

# Дамп объекта

Ох ты ж! Мало того, что hashcode является адресом - так он же ещё и записан в заголовке объекта !

обратный порядок байт в дампе обусловлен тем, что это всё сделано на Intel, который использует Little-Endian порядок, т.е порядок от младшего к старшему байту.

Т.е что происходит - hashcode вычистяется как младшие 32 бита адреса, а потом он записывается в заголовок объекта, после чего адрес объекта уже может менятся, а вот уже hashcode нет.

Т.о. предыдущие два эксперимента нам показали, что в какой-то момент времени hashcode объекта таки может быть адресом, но адрес является ненадёжным свойством и его - т.е hashcode надо где-то хранить.

Мы очень сильно отвлеклись с разбирательством адрес - хэшкод, казалось бы можно было бы на этом слайде и закончить - доказывать и опровергать больше нечего. Но мы выбрали хэшкод как наш проводник в мир внутренностей vm и мы всё же хотим показать почему это не самый лучший способ определения хэш-функции.

# Сколько влезет в кучу ?

EXT VERSION:
но продолжим наше разоблачение - следующий эксперимент, которые мы можем сделать голыми руками без каких-либо дополнительных инструментов - это попробовать найти коллизии hashcode используя адрес в качестве hash-функции.

Как и в прошлых экспериментах мы используем размер кучи 256 Мб, часть съест сама vm - и уже зная размер объекта - получается, что в память влезло бы около 15 млн объектов - что значительно меньше максимально возможного положительного значения hashcode - 2х млрд.

SHORT VERSION:
Давайте попытаемся оценить коллизии hashCode используя адрес в качестве hash-функции.

Если будем использовать как и в прошлых экспериментах мы используем размер кучи 256 Мб, пусть даже часть съест сама vm - и зная размер объекта - получается, что в память влезло бы около 15 млн объектов - что значительно меньше максимально возможного положительного значения hashcode - 2х млрд.

Кто согласен с тем, что на таком размере кучи коллизий просто не должно быть ? А кто за коллизии ?

# EXT VERSION: Граница коллизий

И так сам эксперимент по поиску границ коллизий hashcode

основное действо происходит в цикле - будем создавать объекты, и каждый новый объект будет получать новые адреса памяти.

Нашим противником как всегда выступает GC - может взять и удалить объект, на который больше никто не ссылается - и соот-но какой-то иной объект может использовать адрес для нового объекта.

Чтобы избежать этого - мы будем хранить все созданные объекты в gcKeeper. а уникальные значения будем хранить в uniqueHashCodes - чтобы избежать autoboxing и прочих паразитных аллокаций будем использовать koloboke collections, который от бабушки ушёл, т.е вышел из Trove Collections и так же как и Trove умеет хранить примитивы, и он имеет такой же контракт на добавление, как и java.util.Set - если такого значения ещё нет в сете - то вернётся true - и false в противном случае.

Какие наши ожидания и предположения ? Что 15 млн объектов получат уникальные адреса и соот-но 15 млн уникальных значений hashcode после чего закончится память - т.е ожидаем OOM

Кто за OOM ? Кто за коллизии ?

(Показываем код **IdentityHashCodeCollision**, - Запускаем **IdentityHashCodeCollision** и смотрим демо.)

# EXT VERSION:  demo

Произошли коллизии, но почему ?

# EXT VERSION: Молодое поколение


Увы, но наши рассуждения не совместимы с сборщиками мусора, используемыми в обычной жизни - и из эксперимента по перемещению объекта между поколениями мы уже знаем, что объекты создаются в eden, который в нашем случае оказался равен 64Мб - и в этом случае нам удастся создать только 4млн объектов, после чего начнутся коллизии.

на практике мы создали меньше - т.к. накладные расходы на инфраструктуру по сбору объектов так же съели память.

# SHORT VERSION: Граница коллизий
Конечно же должны быть - и наши рассуждения не совместимы с сборщиками мусора, используемыми в обычной жизни - и из эксперимента по перемещению объекта между поколениями мы уже знаем, что объекты создаются в eden, который в нашем случае оказался равен 64Мб - и в этом случае нам удастся создать только 4млн объектов, после чего начнутся коллизии.

проверить это можно экспериментом, схожим с тем, что мы уже делали.

# пространство hashCode

И так, выбрав адрес в качестве hashcode и из-за Eden мы потеряли 10 бит - и из 4х млрд у нас остаётся только 4 млн уникальных значений.

# Граница коллизий - Результаты

Если же не останавливаться после 1ой коллизии, а продолджить - и скажем, собрать первые 10 - то не сложно заметить в общем-то ожидаемый шаблон - после того, как встретили первую коллизию - hashcode начинают строго повторять адреса Eden - более того, разница между адресами - 16 байт - это понятно почему - размер объекта как раз 16 байт - здесь все коллизии приведены так же в 16 системе счисления.

# hashCode → address → memory allocation

Поскольку мы имеем дело с адресами и созданием объектов - сделаем ещё одно отвлечение и рассмотрим вопрос выделения памяти.

Смотрите - в начале мы не задумывались о том, что объект может быть перемещён и утвержение, что hashCode это адрес не выглядило как-то странно, когда мы стали разбираться - нашли несоответствие. Теперь же у нас коллизии ограниченны eden - но действительно ли это всё, что мы знаем ?

Каждый раз, когда вы создаёте новый объект вы фактически резервируете некоторый объём памяти. И задачей выделения и резервирования памяти занимается аллокатор - давайте попробуем сделать модель аллокатора и так, чтобы эта модель в каких-то цифрах соотносилась с реальным поведением.

# Упрощённый memory allocation

 простейший случай выглядит так - считаем, что адреса начинаются от 0 и до memoryPointer уже заняты - если мы хотим попросить ещё немного памяти - то сдвигаем границу memoryPointer и так мы зарезервировали объем памяти от старой границы размером size.

На первый взгляд именно такой аллокатор в действии только что и видили.

Хорош ли такой malloc - что вообще не так с ним ? Есть ли критические замечания ?

# SyncAllocator
Да, предыдущая версия совсем не годилась для работы с многопоточностью и synchronized безусловно теперь её гарантирует.

И логично посмотреть как себя ведёт данный allocator

# SyncAllocator Performance Benchmark

такой вот простой бенчмарк, конечно для модели особой разницы нет сколько байт выделять - 1 или 16 - но я буду использовать 16 - как и размер экземпляра объекта java.lang.Object.

всё это замеряется на 4 нитях - в реальных приложениях их намного больше

# SyncAllocator Performance Benchmark (результаты)

и такой же самый бенчмарк был сделан, но для однопоточного аллокатора. и здесь, и далее я буду использовать схожие графики для сравнения производительности - единица измерения нс на операцию - т.е чем меньше нс тратится на операцию, тем быстрее, и значит лучше.

при 4х параллельных нитях - почти 190нс на одну аллокацию - это очень дорогая аллокация - для сравнения single-threaded allocator, хотя он применим только к однопоточному случаю, почти в 100 раз дешевле - пока это будет наш ориентир

# Можно ли лучше ?

Можно ли лучше ? Есть какие-нибудь идеи ?

# Compare-and-Swap

Кто-нибудь слышал про Compare-and-Swap ? CAS это операция атомарного сравнения-и-изменения значения, которая реализованая на многих железных архитектурах - и x86, и SPARC, и ARM

# CAS Allocator
Так давайте же сделаем allocator на основе CAS - AtomicLong как раз представляет обёртку вокруг cas для операций с long - getAndAdd атомарная операция на основе CAS'а - получаем старое значение и увеличиваем на size.

и как всегда померяем - стало ли лучше ?

# Allocators Performance Benchmark
Так же 4 нити - стало лучше - почти в 2 раза, но не сильно лучше - 74 нс на операцию очень дорого - мы всё так же далеки от идеала.

Вообще сравнивать производительность в 4х нитях и в одной - не совсем корректно - слишком уж грубый ориентир - можно же выбрать более достоверный ориентир.

Сравним наш моделируемый эксперимент с реальным выделением памяти - т.е как сама VM выделяет память.

# Java Allocation

Опять простой бенчмарк и так же на 4 нитях - как мы помним размер объекта 16 байт - и теперь наше моделирование по условиям измерения очень близко к реальному случаю.

# Java Allocation (результаты)

и результаты, которые наглядно демонстрируют, что наша модель очень далека от реального случая.

# Можно ли ещё лучше ?

Определённо хочется улучшить нашу модель аллокатора.

У нас уже есть некоторое понимание того, что адрес как hashcode - это не очень хорошая хэш-функция, потому, что много коллизий. Коллизии это тоже инструмент для исследования - такой хороший молоток.

Так вот давайте этим молотком постучим - по крайней мере мы знаем, что границы обусловлены размерами eden.

# Распеделение hashCode по нитям

Но как hashcode при этом распределены? - и особенно в разных нитях. В нашем предположении, что hashcode вычисляется как адрес - это равносильно тому как распределены адреса объектов по нитям.

# Распеделение hashCode : Ожидания

Для наглядности я буду так же использовать 4 нити, а чтобы одна нить не убегала вперёд другой будем использовать барьер, чтобы каждая нить создавала N-ый объект и получала его hashcode - только тогда, когда все другие нити дошли до N-го шага.

Конечно же ожидаем увидеть разницу в 16 байт между объектами в разных нитях на каждом из этапов.

И ещё одно ожидание, что при размере кучи в 256Мб, что всего мы сможем создать не больше 4 млн уникальных значений hashcode.

# Распределение hashCode по 4 нитям

Так вот выглядит реальное распределение hashcode по 4м нитям в предположении, что это адрес объекта

у меня меня две новости - одна плохая, и хорошая.

плохая новость в том, что количество уникальных объектов, которые можно создать на одну нить становится тем меньше, чем больше у нас нитей создают новые объекты - в общем-то как мы и ожидали.

дополнительные линии показывают начала коллизий по hashcode - фактически после этого адреса, адреса объектов, а следовательно и hashcode начинают строго повторяться.

# Плохая новость : 1 млн уникальных значений

Т.е если формально посчитать - количество уникальных значений при известном размере Eden - у нас это 64 мб, размере объекта 16 байт и количестве нитей - 4 - мы получаем 1 млн уникальных значений.

т.о наш hashcode теряет ещё 2 бита - и это понятно - нитей было 4 - было бы 8 нитей - потеряли бы 3 бита. в реальных приложениях нитей ещё куда больше - а следовательно и количество уникальных hashcode, которые могут в этой нити появится - ещё меньше. а это быстрый путь к частым коллизиям.

# Хорошая новость

Хорошая новость несколько неожиданная - адреса объектов в пределах одной нити отстоят далеко от адресов объектов других нитей - т.е. совсем не так как мы ожидали.

в силу масштаба адресного пространства кажется, что это почти вертикальные линии, на самом деле наклон очень слабый - разница 16 байт между каждым последующим объектом внутри нити, но не между нитями. а вот разница адресов между нитями - около 700kb.

т.е словно у каждой нити есть свой собственный маленький Eden.

это наблюдение нам поможет существенно улучшить нашу модель аллокатора.

# Даёшь БОЛЬШИЕ куски памяти ! (1)

Вернёмся же к нему - и напилим такой аллокатор, который будет резервировать память большими кусками синхронно, а внутри потока он будет работать как старый добрый простейший однопоточный. и дадим ему кодовое имя - TLAB

Да код не такой уж читаемый - SIZE - это размер большого куска - для примера 1Мб

# Даёшь БОЛЬШИЕ куски памяти ! (2)
- memoryPointer такой же как и в cas-allocator - граница занятой памяти, которую будем менять с помощью cas'а

# Даёшь БОЛЬШИЕ куски памяти ! (3)
- а в threadLocal у нас будет лежать объект, хранящий значения об использованной памяти внутри нити.

# Allocators Performance Benchmark

и снова померяем - стало ли лучше ?

# Allocators Performance Benchmark (результаты)

Круто - вот это уже выглядит намного лучше. Как и в предыдущих замерах - так же все на 4х нитях

# Thread Local Allocation Buffer

Собственно подобным образом и ведёт себя аллокатор в java, используя Thread Local Allocation Buffer - каждая нить запрашивает кусок памяти из Eden, и внутри своей нити уже выдаёт без каких-либо блокировок - маленькая проверка - не вышли ли мы за пределы зарезервированного объёма.

# Thread Local Allocation Buffer (2)
Когда один TLAB заполнен - запрашивается другой кусок - через блокировки - может быть чуть большего размера

Когда нельзя уже больше выделить новый кусок TLAB - случается GC - он решает, что делать с объектами - убивать или перемещать их в другое место. При этом весь Eden снова чист - и после чего TLABы снова могут пилить Eden.

# Стоимость TLAB

И для наглядности - осталось только оценить стоимость TLAB в java - есть ли какой-то выигрыш или нет.

# Стоимость TLAB - результаты
Так же, как и моделируемом аллокаторе я использовал 4 нити - и заметно, что аллокакция с TLAB значительно лучше, чем без неё - почти в 50 раз

у кого java тормозит? запустите ваше приложение с отключённым TLAB и узнайте насколько раньше оно быстро работало.

вообще надо сказать в системах, где нити не являются примитивами системы - сложно добится таких же результатов как в случае, когда и нити, и сборка мусора - а соответственно и аллокации - тесно связаны друг с другом.

# 32bit → 20bit

Итак, подведём итоги экспериментов - использование GC и идеи поколений, быстрой аллокации и TLAB приводят к тому, что hashCode из 32х бит потерял большУю часть - и это всего при 4х нитях. Коллизии начинают встречаться уже через какой-то миллион новых объектов, после чего все значения строго повторяются.

Мы сами загнали себя в угол с идей использовать адрес в hash-функции - плохая выходит hash-функция с очень большим числом коллизий.

# Может быть Random ?
Может быть ну его нафиг и взять какой-нибудь генератор случайных чисел ?

Что будет с коллизиями в этом случае ?

Зал - а вообще насколько должен быть большой набор ключей, чтобы хотя бы у двух каких-либо ключей совпал hashcode ?

Нет, ну это очевидно, когда у нас будет 4 млрд значений - то со 100% вероятностью, что хотя бы одна коллизия да будет.

Что нам ответит математика на этот вопрос ?

# Парадокс дней рождения
есть такой парадокс - парадокс дней рождений - у двух людей с вероятностью 50% совпадёт день рождения в группе уже из 23х человек.
Можно вывести общую формулу подсчитывая вероятности - d - количество вариантов - 32 бита для нашего случая - мы получим дикие числа - особенно 2^32 факториал, но существует формула приближения

так, что не мучаемся - подставляем и считаем - на удивление это всего лишь 77 тыс.

Т.е, если у нас есть 77 тыс ключей, то с вероятностью 50% у двух ключей совпадут hashcode - но не как в случае с адресом, когда значения начнут после некоторого порога строго повторяться.

# -XX:hashCode

Дамы и Господа, Ladies and Gentelmen - пришло время открыть карты - это была ловкость рук и никакого мошенничества - умелое жонглирование с параметрами виртуальной машины!

По-умолчанию hashcode в java это всё-таки просто случайное число и все предыдущие демо были проведены с режимом, когда hashcode вычисляется на основании текущего адреса объекта для того, чтобы показать насколько абсурдна эта идея и что есть много других, более серьёзных и важных задач в архитектуре, чем увязывать hashcode и адрес

Этим флагом можно переключать vm в разные режимы генерации hashcode - раньше, до 8ки, по-умолчанию эта был 0ой режим - использоваться генератор псевдослучайный чисел Парк-Миллера, а начиная с 8ки используется 5ый режим - генератор псевдослучайных чисел Марсальи, по своей сути ThreadLocal генератор случайных чисел

Для предыдущих экспериментов, где требовалось, чтобы работало предположение, что hashcode это адрес - я использовал режим #4 - 1ый режим по своей сути ничем принципиально не отличается от генерации на основании адреса. И режим #2, который возвращает всегда единицу - хорошее испытание для работы алгоритма по разрешению коллизий.

# Дамп объекта при -XX:hashCode=5

И на последок - дамп памяти объекта при флаге по-умолчанию, т.е hashCode = 5. Да, хэшкод хранится всё так же хранится в заголовке объекта, но с адресом никак не связан.

# Распределение hashCode 10 млн об-в в 10 нитях

И на последок, для наглядности сравним гистограму распределения hashcode по 10 млн объектов в 10 нитях в разных режимах - по адресу - синим, и на основе генератора случайных чисел - красным

Как и ожидали раньше - hashcode от случайного числа равномерно распределен по числовой оси, да есть коллизии - их около 23 тыс
И hashcode на основании адреса - в очень узкой полоске, которая соответсвует адресному пространству eden - и количество коллизий чуть больше миллиона - фактически 10%

# Вычислялся ли hashCode

Смотрите, ещё одно интересное наблюдение из нашей модели аллокатора - создание объекта в java занимает столько же времени, как и модель +- в пределах ошибки. и судя по всему - hashcode вообще не вычисляется, когда объект создаётся

Проверим ?

# Object.hashCode() benchmark

пилим такой же benchmark как и раньше - только ещё явно вызываем hashcode,

и для чистоты эксперимента benchmark, который будет только читать hashcode из заголовка объекта - само вычисление будет произведено, но на стадии разогрева benchmark

# Object.hashCode() benchmark (результаты)

Сравнив результаты по созданию объекта, и чтению hashcode из заголовка объекта, можно заключить, что вычисление hashcode как псевдослучайного числа и его запись в заголовок это не дешёвая задача

Так, а что же у объекта там, где всегда записан hashcode, пока он ещё ни разу не вызван ?

# Дамп объекта, сразу после создания

Да ничего у него там - у него там нули - мы опять используем JOL для снятия дампа объекта

* вычислять сразу hashCode - дорого
* hashCode может быть и переопределён
* но место под system hashCode выделено у всех объектов - это не сложно проверить сделав дамп для любого другого класса

но к чему тогда пустовать 4 байтам ??? а не приспособить ли VM их под что-то полезное ?

зал - какое ещё есть собственное свойство, присущее любому объекту в java ?

# monitor

методы wait/notify напоминают, что это конечно же монитор

# Biased Locking

Не редко бывает так, что объект является thread-safe, но по факту он используется почти всегда одной нитью, и очень редко когда какая-то другая нить захватыает его монитор.

особенно это харакетрно для наследия java 1.1 - vector, hashtable, properties, StringBuffer и других - у них все методы синхронизированы

Захват от отпускание монитора это не дешевые операции - поэтому изыскиваются возможности как облегчить. А что если не сделать так - если монитор уже был захвачем данной нитью - то как-то его пометить, привязать к этой нитке. Это и есть основная идея Biased locking.

Вот именно этот маркер нити для biased locking и размещается в этих вакантных 4х байтах.

Надо сказать, что biased locking куда обширней тема, но я рассмотрю её в связке с hashcode

# Biased Locking demo

Если теперь захватим монитор объекта - то в заголовок объекта записывается id нити - id нити можно получить, например, используя thread dump, инструментами типа jvisualvm или через один com.sun MBean

# StringBufferPerfTest

И чтобы показать эффект - давайте напилим такой вот бенчмарк - создавать строку из StringBuffer - только одна нить - в режиме biased locking и без него

# StringBufferPerfTest BiasedLockingStartupDelay

по-умолчанию есть задержка на включение BiasedLocking - её можно отключить этим вот флагом

# StringBufferPerfTest результаты

И поскольку у StringBuffer все методы синхронизированы - и это как раз случай biased locking - и видно, что без него - захват монитора дороже

# identityHashCode

Так и что же происходит, когда надо записать hashCode ? Ведь есть место только для одного из них - либо hashcode, либо BiasedLocking

Добавим ещё один StringBuffer, у которого в заголовке записан hashcode как у java.lang.Object

# identityHashCode
добится этого можно используя System.identityHashCode - т.е смотрите - мы один раз - перед самим benchmark вызываем identityHashCode, и никаких изменений в теле самого benchmark

# identityHashCode результаты

и как результат - объект с системным hashcode ведёт себя точно так же, как и в случае, когда biased locking отключён.

# Revoke Biased Locking

т.е system identityHashCode отзывает biased locking - И в таком случае захват монитора снова становится дорогим. у BiasedLocking ещё несколько краевых случаев, когда он может быть отозван.

Вообще не стоит воспринимать BiasedLocking как панацею - это скорее такой способ как облегчить legacy код, наследство из java 1.1 - на практике, как правило, редко приходится использовать и монитор объекта, и его системный hashcode, так, что отзыв BiasedLocking по причине identityHashCode случается на практике редко

# Заключение

И в заключении:
* Hash структуры данных это одни из быстрых структур данных,
* Используя свои собственные ключи - не забывайте переоределять не только hashcode и equals, но и серьёзно рассматривайте возможность реализации интерфейс Comparable - это защитит вас в случае средне-плохого универсального способа вычисления hashcode - новой редакции Effective Java пока ещё нет, но я больше, чем уверен - это будет там.
* Хотите, чтобы было ещё лучше и меньше коллизий - исследуйте свои hash-функции не только на предмет абсолютных коллизий, но и на предмет коллизий после мастшабирования на размеры массива - это может сократить расход памяти.
* точно можно сказать - hashcode это не адрес объекта. По крайней мере, по-умолчанию.
* жанглируя флагами vm из протёкшей абстракции Object.HashCode можно увидеть уши нескольких отличных инженерных решений в архитектуре - это и копирующий GC, и быстрые аллокации, и облегчённый завхат монитора, но не злоупотербляйте System.identityHashCode.
* Meten is weten - выражение в голландском языке - буквально - измерение это знание - многие наивные рассуждения разбиваются в дребезги о реальность изменений

# Контакты

Все демо и слайды доступны на github-е. Спасибо.
