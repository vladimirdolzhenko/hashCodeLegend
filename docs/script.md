*2017-04-08*

# preparation
* Idea
    * default (белая) тема
    * отключить show whitespaces
    * presentation mode
* MacOsX settings
    * Dock - automatically hide and show Dock
* Выключить все IM!

# Внутрь VM сквозь замочную скважину hashCode
```Меня зовут Владимир и мы будем сквозь замочную скважину hashcode заглядывать внутрь JVM. Более точнее - OpenJDK и OracleJDK```, как самые доступные и самые распострённые реализации java vm.

# no warranty

:godmode: :godmode:  **```всё, что вы здесь услышите - это моя личная точка зрения, которая может быть ошибочна.```**

# план
> * в начале вспомним теорию, а именно ассоциативные массивы и как они устроены.
> * расскажу о классическом способе вычисления hashcode
> * и как можно используя эти знания устроить DoS атаку, и как вылечить её
> * и затем окунёмся в детали виртуальной машины - разрушим старый миф, будут и потроха - сборщик мусора, и аллокация, и немного баттлов - конечно же при этом мне нужны будут ваши голоса - не стесняйтесь поднимать руки
> * естественно мне придётся использовать джентельменский набор инженера - коснёмся и JMH, и Java Object Layout
> * и на последок ещё один трюк виртуальной машины и как hashcode может всё изменить

# Ассоциативный массив / Dictionary / Map
ассоциативный массив - что это такое? ```Это структура данных, позволяющая хранить пары ключ-значение и поддерживающая операции вставки, поиска и удаления по ключу.```

Как она устроена внутри ? Как правило, ```ассоциативный массив реализуется как два массива - один для ключей, другой для значения.``` _Например_, у нас есть телефонная книга - ключом будет выступать имя, а значением будет его номер телефона.

Идея заключается в том, что ```используя hash-функцию можно отобразить ключ на число``` - и вычистлить индекс в массиве, куда записать ключ и соответственно значение.

важный момент - ```поскольку число может быть любым - как очень большим - так и отрицательным, а доступная память ограничена - поэтому полученное число предстоит ещё нормализовать, т.е отмасштабировать на длину массива``` - например, можно использовать остаток от деления на длину массива.

# javadoc
```За hash-функцией далеко ходить не надо``` - у java.lang.Object - корневого класса всей иерархии классов в java - определен метод hashcode - ```т.е по сути каждый объект в java обладают некоторой стандартной hash-функцией.```

Так же обратим внимание, что hashcode возвращает int - это знаковое 32х битное целое число.

# Записать ( Алексей, +791… )

рассмотрим поясняющий пример - допустим уже записано несколько адресатов и надо записать Алексея - и его телефонный номер. **```Предположим```**, что его hashcode равен 23 - ```для пояснения работы это не принципиально```, но о том как именно вычисляется hashcode мы вернёмся позже.

И так - ```вычисляем индекс в массиве и записываем значение```.

# сложность

алгоритм поиска выглядит примерно так же - ``вычисляем hashcode, мастшабируем и проверяем ключ, что записанный ключ равен искомому``.

```т.е вставка, поиск никак не зависят от длины массива - сложность константа```.

**```это самое главное свойство ассоцитивного массива```**.

# Контракт hashCode

```одно из ключевых свойств hashcode - это не изменчивость и постоянство``` - и опредён контракт для hashcode -  этот метод должен постоянно возвращать одно и то же значение.

# Нарушение контракта hashCode

```если бы не было бы этого контракта - и hashCode мог меняться - например, для Алексея он стал бы отличным от того, что было когда записали ключ-значение - то мы уже не найдём его.```

# Коллизии

и **ложка дёгтя** - что, если нам предстоит записать Alexander, Alex и Jan - и, **```предположим, что у всех такой же hashcode, как и у Алексея```**.

Совпадение hashcode ключей - ```это коллизия, и её придётся как-то разрешать - ситуация не приятная, но типичная```.

Надо сказать, что коллизии это самая большая проблема в хэш-структурах - ```используют и разные подходы для разрешия коллизий, и чтобы их не допустить - стараются найти хэш-функцию получше, но для общего случая её сложно подобрать```.

И т.к ```такой идеальной функции нет - то используют то, что есть - а есть то, что либо вернул метод hashCode()``` - и что там пользователь напишет - может быть ужас-ужас.

# Chaining

Существует несколько ```широкораспостраннёных способов``` разрешать коллизии - и ```chaining один из них```. По сути надо создать список и поместить все ключи с одинаковыми hashcode в него. способ универсальный, но далек от идеала, и как плата за это - сложность поиска становится линейной.

# Открытая адресация

другой способ разрешения коллизий - который, называется **```открытая адрессация```** - использует вариацию представления списка и заключается в том, что ```исходный массив ключей используется как список для разрешения коллизии и в нём делается последовательность проб``` относительно исходного индекса - если ячейка занята - делают следующую пробу - например, выбирают соседнюю слева ячейку.

# Открытая адресация (сложность)

если же и она занята - делают ещё пробу и так до тех пор пока не будет найдена свободная ячейка.

```очевидный плюс - не нужна дополнительная структура данных и компактное размещение данных.```

```но и в этом случае сложность деградирует до линейной, если коллизий много```.

**```Это очень важный момент - коллизии способны сломать производительность, и чем больше коллизий, тем только хуже операции типа поиска, вставки и т.п```**

# hashCode = функция ( содержимое объекта )

Как же вычисляется hashCode ? ```как правило hash-функция это некоторая функция над содержимым объекта```.

И хорошо бы знать, как он должен быть как-то вычислен - ведь не важно - получили ли мы строку по сети, или пользователь ввёл в форму данные, или как-то ещё - ключ один и тот же с точки зрения содержимого - т.е они равны с точки зрения equals - а следовательно и hashcode должен быть один и тот же.

Т.е, что строки java, что экземпляры 42 - каждый из них имеет один и тот же hashcode соответственно.

Вообще, ```строго говоря - в качестве hashcode может быть всё, что угодно - хотите возвращайте константу, но тогда можно забыть об быстром доступе по ключу. Т.е. чем лучше будет hash-функция и чем меньше будет коллизий - тем будет лучше```.

Определяя hashcode не забывайте определить equals, который должен использовать те же свойсва для равенства, что и использует hashcode.

# Полиномиальный hashCode

У Джошуа Блоха в его книге Effective Java вычислению hashcode посвящёна отдельная глава -

```Традиционно для общего случая рекомендуется использовать полином по свойствам класса с простыми весами, например 31 - простые числа выбираются опять же в угоду минимизации коллизий - и с другой стороны мы хотим, чтобы метод был относительно простой и не требовал много ресурсов на вычисление```.

Как правило, **```общий случай решает усреднённую задачу, для большинства случаев```** - однако, если у вас узко специализированная задача и вы знаете диапозон допустимых значений - то можно подобрать другие коэффециенты дабы минимизировать коллизии.

# String.hashCode()

И как раз ```одну из типичных полиминальных реализаций hashCode можно увидеть в строке - складываем все элементы массива с весами по степеням 31```.

так же иногда применяют lazy вычисление и кэширирование уже вычисленного значения.

# String.hashCode() javadoc
Да - и более того - ```этот алгоритм вычисления так же прописан в javadoc к этому методу``` - и это **```значит, что это часть публичного API и все сертифицированые реализации JVM обязаны быть полином с весом 31```**.

**```Но почему именно 31 ? Не 2, не 5, а именно 31```** ? Есть идеи ?

# java v.1.1.1 - String.hashCode()

в самых первых версиях java hashcode для строки ```вычислялся архаичным способом``` - здесь и разные коэффециенты при разных длиннах строк, и пропуск отдельных символов - жуть

```И тот же Джошуа Блох решил это исправить```

# 31 : Детективная история

Есть такой ```замечательный баг``` - который как раз посвящён исправлению архичному вычислению hashcode

- в книге Kernighan и Ritchie - Язык программирования Си - был дан готовый рецепт - и без доказательно даётся полиминальная функция с числом 31 - тогда Джошуа связался с Брайном Керниганом - но тот забыл уже откуда он взял это число - просто оно работает.

Блох ```провёл небольшое исследование``` - взял слова и словоформы из словаря Merriam-Webster, все строки в солярисе в /bin/*, /usr/bin/* и т.д - и на последок он запустил веб-паука, который за несколько часов собрал ему около 30 тыс урлов - сейчас это выглядит более, чем забавно - но 20 лет назад таков был интернет.

И вот он собрал все эти строки и проанализировал уровень коллизий - та, реализация, которая была на тот момент давала очень высокий уровень коллизий, а уровень коллизий при коэффециентах 31, 33 и 37 оказался примерно одинаковый. + 31 достаточно близко к 32, так, что многие компиляторы могут представить умножение 31 как сдвиг и вычитание.

**```в результате было выбрано число 31 - как и у Kernighan и Ritchie. В чём-то это Ответ на главный вопрос жизни, вселенной и всего такого в java```**.

# Но ведь можно подобрать…

Но ведь далеко не все строки это осмысленные слова - можно же подобрать такие значения, ```которые будут иметь один и тот же hash code, зная как он вычисляется```.

```строки Аа и ББ - один самых известных примеров```

```Возьмём два рядом стоящих символа в строке - если уменьшаем левый на 1, то правый - надо увеличить на 31.
Или наоборот, если левый увеличиваем на 1 - то правый уменьшаем на 31```.

Подобный приём можно применить для двух символов, между которыми находится ещё один, и т.д. Проще всего искать строки такой же длины - отталкиваясь от уже существующей строки - хотя конечно можно искать и варианты с бОльшей длиной строки - играя на переполнении целого числа.

```Для примера я взял строку "username" и направленным поиском - меняя соседние символы - нашёл почти полмиллиона вариантов```. Хотя даже этого оказалось много.

и давайте измеряем влияние коллизий.

:bangbang: :bangbang: ```и здесь и далее я буду использовать jmh для измерения производительности```

# Java Microbenchmark Harness

> :raised_hands: :raised_hands:
> * поднимите руки, если в зале кто-то не знает или не слышал о jmh ?
> * а теперь, кто что-то хотя бы слышал о нём.
> * и кто его и знает, и использует или иногда использует.

Если кто не знает - буквально кратко - что это и зачем - ```написать бенчмарк не составляет особого труда, но написать корректный бенчмарк, который будет действительно правильно измерять и измерять именно то, что хочется - это значительно сложнее```.

```jmh это фреймфорк по написанию правильных nano/micro/milli performance benchmarks для java. он составляет часть openjdk toolset и так же люди из openjdk его поддерживают и развивают.```

# JMH :: "username" коллизии :: benchmark (1)

Поскольку я ```буду не один раз прибегать к использованию JMH - давайте я на конкеретном примере покажу, что и как можно получить используя jmh```.
Примерно вот так или подобно так выглядит benchmark - у нас есть ```само тело бенчмарка - добавить ключи в map'у```

# JMH :: "username" коллизии :: benchmark (2)
```можно указывать как долго надо разогревать VM, дабы исключить краевые эффекты связанные с jit компиляцией, прогревом vm и не только, можно указывать как долго надо измерять сам бенчмарк, чтобы получить статистически корректные измерения, можно специфицировать в скольких нитях будет работать бенчмарк```

# JMH :: "username" коллизии :: benchmark (3)
```по аналогии с junit можно специфицировать setup и teardown методы, которые соот-но вываваются перед и после работы тела бенчмарка``` - именно там я загружаю из файла найденные коллизии для строки username - ```всё это вспомогательные операции для самого бенчмарка```. и так же по аналогии с junit можно параметризовать benchmark - я хочу проследить за производительностью при разном количестве коллизий.

конечно - **```это не избавляет от того, чтобы писать неправильные benchmark-и и/или неправильно их трактовать```** - если ещё не делали - смотрите записи Алексея Шипилёва, где он подробно расскаывает о jmh, на сайте проекта есть подробные примеры.

словом - **```jmh - важный и полезный инструмент в руках инженера```**.

```и давайте уже посмотрим, что у нас получается``` ?

# "username" коллизии :: java7 результаты

> :raised_hands: :raised_hands: кто ещё свои приложения в проде держит на 7ке ?  или на 6ке ?)

```легко можно заметить параболу на графике``` - т.е у нас квадратичная сложность - если честно - я не ожидал увидеть время отклика 1.5 минуты, передавая 200 тыс ключей.

```Откуда пробелема возникла```, думаю уже понятно - почти в самом начале я рассказывал про коллизии - и для их разрешения ```использовали chaining```.

> Если посмотреть как обрабатываются cookies, или параметры http-запроса в Tomcat'е - то там используется как раз LinkedHashMap - но для случая вставки ключей это ничем не лучше обычного HashMap. А после того, как все ключи из запроса будут загружены в map - приложение, или сервлет ищет нужный ему параметр - собственно поэтому я и выбрал в качестве ключа "username" - достаточно часто используемое имя параметра. А поиск ключа в мапе, в которой его нет, но есть много коллизий - заставит перебрать все ключи с одинаковым hashcode - а это ещё немного усугубит проблему.

> во время измерений я смотрел за загрузкой cpu - и на все эти 1.5 минуты одно ядро было загружено под 100% - доклад и конференция не про DOS-атаки, но идея думаю более, чем ясна.

Что нам делать ?

# ещё одна функция нужна

**```Нужно выйти за рамки существующих возможностей```** - одна из вариаций разрешения коллизий в открытой адресации заключется в использовании **```двойного хэширования```**.

Например, в SHA1 нашли коллизии - с очень маленькой вероятностью, у MD5 вероятность коллизий выше - но поскольку базис данных hash-функций разный - то результирующая вероятность коллизий почти, что нулевая.

Идея заключается в том, что взять **```ещё одну функцию - желательно, ортогональной исходной```** - как это, например, может быть вторая hash-функция, либо вообще функция из другой области

# Дополнительная функция: compareTo

```И что у нас уже есть в стандартной библиотеке ? строки, и числа, даты и многие другие классы - все они сравниваемые - т.е у них реализована функция compareTo. Её мы и будем использовать как вторую функцию для разрешения коллизий.```

тогда для разрешения коллизий можно строить бинарное дерево поиска, которое обладает ```логарифической сложностью```.

В java начиная с 8ки - внутри HashMap, LinkedHashMap, ConcurrentHashMap используется красно-чёрное дерево для разрешения коллизияй ```при привышении некоторого порогового числа коллизий``` для конкретной ячейки.

# Chaining и Красно-Чёрное-Дерево

```пока уровень коллизий мал, а именно меньше 8 элементов, то там по прежнему chaining.```

> Если у вас есть сомнения относительно коллизий в вашем приложении - самый простой способ их оценить - это снять heapdump и посмотреть количество экземпляров TreeNode - они появляются тогда, когда уровень коллизий больше 8, если же уровень коллизий мал - то chaining и будут экземпляры класса Node

```давайте же посмотрим на результаты работы данного подхода```.

# "username" коллизии :: map.put(key, key)

вот сравнение того же самого теста с коллизиями по username ```в 7ке и в 8ке``` - вот тот график, который слабо отличается от нуля - это 8ка - ибо там совершенно другой масштаб времени - положить все 200 тыс ключей на 8ке занимает ```где-то 100 мс на моей машине```

**```основной эффект прежде всего из-за изменения внутренней реализации hashmap - если сделать backport hashmap из 8ки в 7ку - то цифры будут схожими с теми, что мы видим для 8ки```**.

# "username" коллизии :: 500x zoom-in

если изменить масштаб в 500 раз - обратите внимание на шкалу времени - это миллисекунды - 7ка сразу ушла в небеса - точка возле 200 мс это при 1000 ключей - а ```8ка кажется, что почти линейна, хотя это конечно же слабо растущий логарифм```

# "username" коллизии :: Comparable

Одно очень важное замечание - для того, **```чтобы строить деревья - ключи обязаны быть сравниваемыми```** - т.е реализовывать интерфейс Comparable, но если он не сравниваемый - то нас ждёт ещё более худшая ситуация.

я запустули тот же бенчмарк, но в качестве ключа я использовал не java.lang.String, а класс-обёртку, но который НЕ реализует интерфейс Comparable.

И всё тот же набор ключей, полученный из коллизий по строке username.

проблема заключена в том, что **```дорого обходится попытка внести упорядочивание в естественно неупорядоченные ключи```**

> Т.е. если вы каким-то образом получаете данные из не надёжного источника - н-р внешняя сеть - и по каким-то причинам используете свои классы в качестве ключей - например, пары или кортежи в качестве ключей - стоит рассмотреть возможность реализации Comparable - хотя не всегда это может быть и естественный порядок.

# утёкшая абстракция

> Как вычислять hashcode у которого нет данных ? hashcode определён у java.lang.Object - значит все классы, которые не переопределяют этот метод - ведут себя точно так же. И что же собственно он возвращает ?
>
> Вообще это очень странно, когда корневой класс иерархии содержит в себе метод ради реализации ассоцитивного массива.
> Например, существует интерфейс Comparable для сравнения объектов, но нет интерфейса Hashable.
>
> Надо сказать, что наличие этого метода у Object с реализацией по-умолчанию повлекло за собой последствия, из-за которых мы можем заглянуть в дебри виртуальной машины исследуя его.

# Urban Legend

Более того - это даже породило легенду, ещё более бородатую, чем я - которая гласит, что **```hashcode это адрес объекта```** - т.е этот метот можно записать что-то в виде такого кода на Си

# Urban Legend: Первоисточник

```Первоисточником легенды является всё тот же javadoc к которому мы уже не раз обращались``` - и в нём сказано, что типичная реализация метода hashcode у java.lang.Object это преобразование внутреннего адреса объекта к числу.

**```Попробуем не только разрушить этот миф, но и наглядно показать, почему это не самый лучший выбор и проникнуть внутрь VM```**.

И так - **```предположим, что hashcode объекта это всё таки его адрес. В качестве инструмента будем использовать конечно же сам hashcode - и его свойства - неизменчивость и распределение значений. Будем проверять разные предположения на корректность при помощи тестов```**.

# Адрес объекта

вообще, первое, что приходит на ум, когда слышишь утверждение "hashcode использует адрес объекта" - это взять и проверить.

Как **```надёжно получить адрес объекта ?```** Мало того, что ```в java отстутсвует арифметика указателей на уровне языка - как, например, в Си```, так ещё и hashcode это только 32 бита, а адрес объекта в современном мире 64х битных платформ - может быть запросто быть больше 32х бит.

# native method

Если мы посмотрим на исходный java код java.lang.Object - то увидим, что этот метод является native - т.е он ```реализован на уровне самой VM```.

# Шипилёв-слайд

> :raised_hands: :raised_hands: Кто любит unsafe ?

> Конечно же можно при помощи unsafe получить адрес объекта - но подводных камней очень много - и то, что нельзя его создать через оператор new - обычно воруют экземпляр через reflection, и что в самом unsafe нет метода по получению адреса объекта - и в довершение - размер указателя объекта может быть как 32 бита даже на 64х битной java, но может быть и 64 - словом вагон головных болей, неожиданностей, corrupted memory от неумелого обращения с адресной арифметикой - в конце концов это приватный API, который должен закрыт.

**```Основная причина почему unsafe стал столь популярен - не было альтернатив```**.

# Java Object Layout

для задач проведения анализа компоновки объекта, его адреса, размера, расположение полей, сколько байт занимают - **```есть альтернатива, созданная людьми из openjdk - Java Object Layout```**.

И конечно же он сразу же из коробки даёт возможность получить - и адрес объекта, и его размер, можно достаточно просто снять дамп объекта и посмотреть его содержимое - без каких-либо Unsafe и прочей магии с головыми болями - всё это спрятанно как-то там внутри. В конце-концов авторы openjdk лучше знают и об внутреннем устройстве объекта, обо всех краевых случаях.

**```Словом - давайте забудем про Unsafe и будем использовать JOL```**.

# JOL : пример

> :raised_hands: :raised_hands: Кто из вас слышал и использовал Java Object Layout ?

И если JMH как инструмент неплохо известен - то о JOL мало кто-то знает - давайте покажу один из примеров использования

```пусть у вас есть класс - pair - составной ключ, состоящий из двух ключей,``` и вы захотели добавить поле - hashcode - чтобы его закэшировать и не вычислять каждый раз - как это сделано у String, например.

на сколько изменится потребление памяти ? int же 4 байта ?

> :raised_hands: :raised_hands: кто за то, что потребление памяти увеличится на 4 байта на каждый объект Pair2 ? а кто за какое-то другое число ?

# -XX:+UseCompressedOops и heap < 4Gb

и JOL даёт ответ... **```ни на сколько не изменится, если у вас меньше 4х гб хипа и включёно сжатие указателей```** - а оно включёно по-умолчанию.

# -XX:+UseCompressedOops и heap < 4Gb (детализация)

детализация, которую даёт JOL показывает что ```это произошло из-за чтого, что есть выравнивание объектов на 8 байт. и когда мы добавили hashcode - мы как раз использовали этот ранее не использованный зазор```.

# JOL : -XX:-UseCompressedOops или heap > 4Gb

Но если у вас больше 4х гб или отключено сжатие указателей - ```объект будет потреблять не на 4 байта больше - а на 8 байт больше```

# JOL : -XX:-UseCompressedOops или heap > 4Gb  (детализация)

**```изменились и размеры указателей```**, и тоже выравнивание размеров объекта по 8 байтам - более того - видно, что ```свойство hashcode теперь располагается в начале объекта - т.к физическое распложение полей в runtime в java может значительно отличаться от того, что задеркларировано```.
**```вот на все подобные вопросы и поможет ответить JOL```**.

# Адрес и hashCode

```вернёмся же к hashcode - при помощи одного флага VM - мы можем добится того, что наше предположение будет истино```.
```Наглядней всего заметно сходство, если мы представим всё в 16 системе счисления - hashcode использует младшие 32 бита адреса```, тут же и видим размер объекта - 16 байт.
Что же - ```теперь можно смело исследовать влияние такой реализации hash-функции и что мы можем увидеть через призму этого предположения```.

# Следим за адресом объекта (1)

И первый эксперимент - проверить **```насколько можно доверять адресу объекта```** - для проверки этой гипотезы давайте создадим новый объект - theObject - в данном демо это будет главная цель нашего наблюдения - зафиксируем адрес этого объекта в самом начале

# Следим за адресом объекта (2)

затем будем создавать другие объекты и, чтобы избежать того, чтобы GC собрал их как мусор - будем хранить их в списке gcKeeper.

# Следим за адресом объекта (3)

Основная цель - следить за адресом объекта theObject - как только адрес изменится -  мы выйдем из цикла и прекратим создавать объекты. Но может, что адрес никогда не изменится и мы получим OOM.

# Следим за адресом объекта (4)

В демонстрационных целях - **```чтобы не ждать OOM долго```** - я ограничу размер кучи до 256Мб. И использую SerialGC - тот же самый эффект при других сборщиках мусора, возможно с небольшой разницой по цифрам.

> :raised_hands: :raised_hands:  И так - голосуем - кто за OOM ? А кто за то, что адрес объекта изменится ?

# demo
> Открываем и показываем **ObjectReallocation** - Запускаем **ObjectReallocation** и смотрим демо.)

```Что произошло ??? Почему ?```

# GC: поколения

> :raised_hands: :raised_hands: зал - кто не слышал про поколения в сборке мусора ? поднимайте, поднимайте руки) и теперь - кто слышал ?

Давайте бегло объясню общую идею - много лет назад была высказана гипотеза, что **```большинство объектов короткоживущие - т.е умирают вскоре после того как они были созданы```** - буквально слоган панков - **```жить быстро, умереть молодым```**.
это сделано из тех соображений, чтобы сборщику мусора обходить не весь граф объектов - а только очень малую часть.

Т.е объекты рождаются в eden, если он не умер молодым, а выжил - то он перемещается в более старшее поколение - survivor, и потом может быть перемещён в старое поколение - GC обходит old gen только во время Full GC время полной сборки.

java использует эту гипотезу о поколениях - и в общем-то она не плохо даже работает - но с ростом объёмов памяти и ростом числа объектов гипотеза уже не так удачно работает как раньше - не так давно стали появлятся другие гипотезы - как например региональная гипотеза, которая реализована в G1 и shenandoah.

# Следим за адресом объекта вместе с GC

Давайте добавим ```дополнительный флаг для запуска VM - а именно будем отслеживать GC и запустим то же самое демо```

(Запускаем **ObjectReallocation (gc)** и смотрим демо.)

Теперь видно, что **```произошла сборка мусора - и более того, по GC логу можно даже понять откуда и куда был перемещён наш объект - рассмотрим его детальней```**

# GC - не только сборка мусора

вот лог такого же запуска - **```объект изначально был создан в eden - и GC переместил его за пределы eden - и именно это мы и заметили```**.

понимаю, что сравнивать 16тиричные числа как-то не удобно - поэтому я **```расположил адреса налача eden, старый т.е исходный адрес объекта, конец eden и новый адрес объекта в порядке возврастания адресов```**

> **т.е. Garbage Collection не просто собирает мусор, но и производит перемещения объектов - это применимо как к сборщикам по поколениям, так и региональным - такие как G1**

# Следим за hashcode

Изменение адреса объекта, порождает следующий эксперимент **```если может изменится адрес - то возможно может и hashcode изменится - мы же помним, что hashCode это адрес объекта, не так ли ?```**

По сути делаем ```всё то же самое, что и в предыдущем эксперименте```, только на этот раз будем **следить не за адресом объекта, а за hashcode** - так же зафиксируем начальное значение, и так же будем создавать новые объекты и хранить их в gcKeeper пока не изменится hashcode, либо не случится OOM

```И так же как и в предыдущем демо размер кучи уменьшил до 256Мб```.

> :raised_hands: :raised_hands: Голосуем - Кто за то, что hashCode изменится ? Прошлый же раз адрес поменялся, а hashcode это же адрес, так ведь ?  А кто за OOM ?

# demo

> показываем код **ObjectHashReallocation** - так же как и в предыдущем демо - отличие от слайда только в сообщении после цикла - Запускаем **ObjectHashReallocation** и смотрим демо.

```Почему ?```

```Объект не может нарушать контракта hashcode, hashCode является собтсвенностью объекта, более того - неизменяемой собтсвенностью.```

Напрашивается вывод, что данное **```свойство где-то хранится и оно является```**

# Скрытое свойство

**```Скрытым свойством```** - Как мы помним - hashcode это native метод, но на уровне java кода ни одного свойства у java.lang.Object не определено. И нам надо идти глубже, и поможет нам в этом снова Java Object Layout !

Давайте при помощи ```JOL сделаем dump объекта - т.е как объект целиком представлен в памяти.```

# Дамп объекта

```Ох ты ж! Мало того, что hashcode является адресом - так он же ещё и записан в заголовке объекта !```

обратный порядок байт в дампе обусловлен тем, что это всё сделано на Intel, который использует Little-Endian порядок, т.е порядок от младшего к старшему байту.

Т.е что происходит - ```hashcode вычистяется как младшие 32 бита адреса, а потом он записывается в заголовок объекта, после чего адрес объекта может менятся, а вот уже hashcode нет.```

```Т.о. предыдущие два эксперимента нам показали, что в какой-то момент времени hashcode объекта таки может быть адресом, но адрес является ненадёжным свойством, и hashcode надо где-то хранить.```

Мы очень сильно отвлеклись с разбирательством адрес - хэшкод, казалось бы можно было бы на этом слайде и закончить - доказывать и опровергать больше нечего. Но ```мы выбрали хэшкод как наш проводник в мир внутренностей vm и мы всё же хотим показать почему это не самый лучший способ определения хэш-функции.```

# Сколько влезет в кучу ?

```Давайте попытаемся оценить коллизии hashCode используя адрес в качестве hash-функции.```

Если будем использовать как и в прошлых экспериментах мы используем размер кучи 256 Мб, пусть даже часть съест сама vm - и зная размер объекта - получается, ```что в память влезло бы около 15 млн объектов - что значительно меньше максимально возможного положительного значения hashcode - 2х млрд.```

> :raised_hands: :raised_hands: Т.е при размере кучи коллизий просто не должно быть - не так ли ? Кто согласен с утверждением, что коллизий не будет ? И теперь кто за коллизии ?

# Граница коллизий
```Конечно же коллизии должны быть - и наши рассуждения не совместимы с сборщиками мусора```, используемыми в обычной жизни - и из эксперимента по перемещению объекта между поколениями мы уже знаем, что объекты создаются в eden, который в нашем случае оказался равен 64Мб - ```и в этом случае нам удастся создать только 4млн объектов, после чего начнутся коллизии```.

```Более того, как только мы встретим первую коллизию значения hashcode будут повторяться - т.к. они будут использовать то же самое адресное пространство eden```.

_проверить это можно экспериментом, схожим с тем, что я проводил при наблюдении за адресом объекта_.

# пространство hashCode

```И так, выбрав адрес в качестве hashcode и из-за Eden мы потеряли 10 бит - и из 4х млрд у нас остаётся только 4 млн уникальных значений.```

# hashCode → address → memory allocation

```Поскольку мы имеем дело с адресами и созданием объектов - сделаем ещё одно отвлечение и рассмотрим вопрос выделения памяти.```

> В начале мы не задумывались о том, что объект может быть перемещён и утвержение, что hashCode это адрес не выглядило как-то странно, когда мы стали разбираться - нашли несоответствие. Теперь же у нас коллизии ограниченны eden - но действительно ли это всё, что мы знаем ?

> Каждый раз, когда вы создаёте новый объект вы фактически резервируете некоторый объём памяти. И задачей выделения и резервирования памяти занимается аллокатор - давайте попробуем сделать модель аллокатора и так, чтобы эта модель в каких-то цифрах соотносилась с реальным поведением.

# Упрощённый memory allocation

 простейший случай выглядит так - ```считаем, что адреса начинаются от 0 и до memoryPointer уже заняты - если мы хотим попросить ещё немного памяти - то сдвигаем границу memoryPointer и так мы зарезервировали объем памяти от старой границы размером size```.

**```На первый взгляд именно такой аллокатор в действии только что и видили```**.

> :raised_hands: :raised_hands: Хорош ли такой malloc - что вообще не так с ним ? Есть ли критические замечания ?

# SyncAllocator
Да, **```предыдущая версия совсем не годилась для работы с многопоточностью и synchronized безусловно теперь её гарантирует```**.

```И логично посмотреть как себя ведёт данный allocator```

# SyncAllocator Performance Benchmark

такой вот простой бенчмарк, конечно для модели особой разницы нет сколько байт выделять - 1 или 16 - но я буду использовать 16 - как и размер экземпляра объекта java.lang.Object.

```всё это замеряется на 4 нитях``` - в реальных приложениях их намного больше

# SyncAllocator Performance Benchmark (результаты)

и ```такой же самый бенчмарк был сделан, но для однопоточного аллокатора.``` **```и здесь, и далее я буду использовать схожие графики для сравнения производительности - единица измерения нс на операцию - т.е чем меньше нс тратится на операцию, тем быстрее, и значит лучше```**.

при 4х параллельных нитях - почти 190нс на одну аллокацию - это очень дорогая аллокация.

:bangbang: :bangbang: **```Строго говоря - нам не так принципиальны абсолютные цифры - конкретно эти цифры я получил на своем лаптопе - на другой машине они могут быть другими - для нас интересней сравнение - кто больше или меньше и во сколько раз больше или меньше```**.

для сравнения single-threaded allocator, хотя он применим только к однопоточному случаю, почти в 100 раз дешевле - пока **```это будет наш ориентир```**

# Можно ли лучше ?

Можно ли лучше ? Есть какие-нибудь идеи ?

# Compare-and-Swap

> :raised_hands: :raised_hands: Кто-нибудь слышал про Compare-and-Swap ? CAS это операция атомарного сравнения-и-изменения значения, которая реализованая на многих железных архитектурах - и x86, и SPARC, и ARM

# CAS Allocator
```Так давайте же сделаем allocator на основе CAS``` - AtomicLong как раз представляет обёртку вокруг cas для операций с long - getAndAdd атомарная операция на основе CAS'а - получаем старое значение и увеличиваем на size.

```и как всегда померяем - стало ли лучше ?```

# Allocators Performance Benchmark
```Так же 4 нити - стало лучше - почти в 2 раза```, но не сильно лучше - 74 нс на операцию очень дорого - **```мы всё так же далеки от идеала```**.

```Вообще сравнивать производительность в 4х нитях и в одной - не совсем корректно - слишком уж грубый ориентир - можно же выбрать более достоверный ориентир```.

```Сравним наш моделируемый эксперимент с реальным выделением памяти - т.е как сама VM выделяет память```.

# Java Allocation

Опять простой бенчмарк и так же на 4 нитях - как мы помним размер объекта 16 байт - и теперь наше моделирование по условиям измерения очень близко к реальному случаю.

# Java Allocation (результаты)

**```и результаты, которые подтверждают, что наша модель очень далека от желаемого```**.

# Можно ли ещё лучше ?

```Определённо хочется улучшить нашу модель аллокатора.```

У нас уже есть некоторое понимание того, что адрес как hashcode - это не очень хорошая хэш-функция, потому, что много коллизий. **```Коллизии это тоже инструмент для исследования - такой хороший отбойный молоток```**.

```Так вот давайте этим молотком постучим - по крайней мере мы знаем границы.```

# Распеделение hashCode по нитям

Но ```как hashcode при этом распределены? - и особенно в разных нитях. В нашем предположении, что hashcode вычисляется как адрес - это равносильно тому как распределены адреса объектов по нитям```.

# Распеделение hashCode : Ожидания

Для наглядности так же используем 4 нити, а чтобы одна нить ```не убегала вперёд другой будем использовать барьер, чтобы каждая нить создавала N-ый объект и получала его hashcode - только тогда, когда все другие нити дошли до N-го шага```.

```Конечно же ожидаем увидеть разницу в 16 байт между объектами в разных нитях на каждом из этапов```.

```И ещё одно ожидание, что при размере кучи в 256Мб, что всего мы сможем создать не больше 4 млн уникальных значений hashcode```.

# Распределение hashCode по 4 нитям

Так вот выглядит реальное распределение hashcode при размере кучи 256мб по 4м нитям в предположении, что это адрес объекта. и как и ожидалось мы органичены 64Мб.

```у меня меня две новости - одна плохая, и хорошая```.

```начнём с плохой - количество уникальных hashCode, которые можно создать на одну нить становится тем меньше, чем больше у нас нитей создают новые объекты - хотя это даже не новость, а вполне логично было ожидать этого```.

пунктирные линии указывают на начало коллизий по hashcode - фактически после этого адреса, адреса объектов, а следовательно и hashcode начинают строго повторяться.

# Хорошая новость

Увеличим масштаб. Хорошая новость несколько неожиданная - ```адреса объектов в пределах одной нити отстоят далеко от адресов объектов других нитей - т.е. совсем не так как мы ожидали```.

в силу масштаба адресного пространства кажется, что это почти вертикальные линии, на самом деле наклон очень слабый - разница 16 байт между каждым последующим объектом внутри нити, но не между нитями. а вот разница адресов между нитями - около 700kb.

**```т.е словно у каждой нити есть свой собственный маленький Eden```**.

используем эту идею для того, чтобы улучшить нашу модель аллокатора.

# Даёшь БОЛЬШИЕ куски памяти ! (1)

Вернёмся же к нему - и напилим такой аллокатор, который будет резервировать память большими кусками синхронно, а внутри потока он будет работать как старый добрый простейший однопоточный. **```дадим ему кодовое имя - TLAB```**

Да код не такой уж читаемый - SIZE - это размер большого куска - для примера 1Мб

# Даёшь БОЛЬШИЕ куски памяти ! (2)
- ```memoryPointer такой же как и в cas-allocator - граница занятой памяти, которую будем менять с помощью CAS'а```

# Даёшь БОЛЬШИЕ куски памяти ! (3)
- ```а в threadLocal у нас будет лежать объект, хранящий значения об использованной памяти внутри нити```.

# Allocators Performance Benchmark

и снова померяем - стало ли лучше ?

# Allocators Performance Benchmark (результаты)

```вот это уже выглядит намного лучше. Как и в предыдущих замерах - так же все на 4х нитях```

# Thread Local Allocation Buffer

```подобным образом и ведёт себя аллокатор в java, используя Thread Local Allocation Buffer``` - каждая нить запрашивает кусок памяти из Eden, и внутри своей нити уже выдаёт без каких-либо блокировок - маленькая проверка - не вышли ли мы за пределы зарезервированного объёма.

# Thread Local Allocation Buffer (2)
```Когда один TLAB заполнен - запрашивается другой кусок``` - **```через блокировки```** - ```может быть чуть большего размера```

Когда нельзя уже больше выделить новый кусок TLAB - случается GC - он решает, что делать с объектами - убивать или перемещать их в другое место. При этом весь Eden снова чист - и после чего TLABы снова могут пилить Eden.

# Стоимость TLAB

```осталось только оценить стоимость TLAB в java - есть ли какой-то выигрыш или нет```.

# Стоимость TLAB - результаты
```Так же, как и моделируемом аллокаторе я использовал 4 нити - и заметно, что аллокакция с TLAB значительно лучше, чем без неё - почти в 50 раз```

> :raised_hands: :raised_hands: у кого java тормозит? запустите ваше приложение с отключённым TLAB и разделите боль аллокатора в Си

вообще надо сказать в системах, где нити не являются примитивами системы - сложно добится таких же результатов как в случае, когда и нити, и сборка мусора - а соответственно и аллокации - тесно связаны друг с другом.

# 32bit → 20bit

Итак, **```подведём итоги экспериментов - использование GC и идеи поколений, быстрой аллокации и TLAB приводят к тому, что hashCode из 32х бит потерял большУю часть - и это всего при 4х нитях. Коллизии начинают встречаться уже через какой-то миллион новых объектов, после чего все значения строго повторяются```**.

```Мы сами загнали себя в угол с идей использовать адрес в hash-функции - плохая выходит hash-функция с очень большим числом коллизий.```

# Может быть Random ?
```Может быть ну его нафиг и взять какой-нибудь генератор случайных чисел ?```

```Что будет с коллизиями в этом случае ?```

> :raised_hands: :raised_hands: Зал - а вообще насколько должен быть большой набор ключей, чтобы хотя бы у двух каких-либо ключей совпал hashcode ?

**```Что нам ответит математика на этот вопрос ?```**

# Парадокс дней рождения
```есть такой парадокс - парадокс дней рождений - у двух людей с вероятностью 50% совпадёт день рождения в группе уже из 23х человек.```
Можно вывести общую формулу подсчитывая вероятности - d - количество вариантов - 32 бита для нашего случая - мы получим дикие числа - особенно 2^32 факториал, но существует формула приближения

```не мучаемся - подставляем и считаем - на удивление это всего лишь 77 тыс.```

Т.е, если у нас есть 77 тыс ключей, то с вероятностью 50% у двух ключей совпадут hashcode - но не как в случае с адресом, когда значения начнут после некоторого порога строго повторяться.

# -XX:hashCode

Дамы и Господа, Ladies and Gentelmen - пришло время открыть карты - это была ловкость рук и никакого мошенничества - умелое жонглирование с параметрами виртуальной машины!

**```По-умолчанию hashcode в java это всё-таки просто случайное число и все предыдущие демо были проведены с режимом, когда hashcode вычисляется на основании текущего адреса объекта для того, чтобы показать насколько абсурдна эта идея и что есть много других, более серьёзных и важных задач в архитектуре, чем увязывать hashcode и адрес```**

Этим флагом можно переключать vm в разные режимы генерации hashcode - раньше, до 8ки, по-умолчанию эта был 0ой режим - использоваться генератор псевдослучайный чисел Парк-Миллера, а начиная с 8ки используется 5ый режим - генератор псевдослучайных чисел Марсальи, по своей сути ThreadLocal генератор случайных чисел

Для предыдущих экспериментов, где требовалось, чтобы работало предположение, что hashcode это адрес - я использовал режим #4 - 1ый режим по своей сути ничем принципиально не отличается от генерации на основании адреса. И режим #2, который возвращает всегда единицу - хорошее испытание для работы алгоритма по разрешению коллизий.

# Дамп объекта при -XX:hashCode=5

Чтобы разубедить обратно - дамп памяти объекта при флаге по-умолчанию, т.е hashCode = 5. ```hashcode хранится всё так же хранится в заголовке объекта, но с адресом никак не связан```.

# Распределение hashCode 10 млн об-в в 10 нитях

```И на последок, для наглядности сравним гистограму распределения hashcode по 10 млн объектов в 10 нитях в разных режимах - по адресу - синим, и на основе генератора случайных чисел - красным```

```Как и ожидали раньше - hashcode от случайного числа равномерно распределен по числовой оси, да есть коллизии - их около 23 тыс```
```И hashcode на основании адреса - в очень узкой полоске, которая соответсвует адресному пространству eden - и количество коллизий больше 10%```

# Вычислялся ли hashCode

```интересное наблюдение из нашей модели аллокатора - создание объекта в java занимает столько же времени, как и модель +- в пределах ошибки. и судя по всему - hashcode вообще не вычисляется, когда объект создаётся```

**```Проверим ?```**

# Object.hashCode() benchmark

```пилим такой же benchmark как и раньше - только ещё явно вызываем hashcode,```

```и для чистоты эксперимента benchmark, который будет только читать hashcode из заголовка объекта - само вычисление будет произведено, но на стадии разогрева benchmark```

# Object.hashCode() benchmark (результаты)

Сравнив результаты по созданию объекта, и чтению hashcode из заголовка объекта, можно заключить, что вычисление hashcode как псевдослучайного числа и его **```запись в заголовок это не дешёвая задача```**

```Так, а что же у объекта там, где всегда записан hashcode, пока он ещё ни разу не вызван ?```

# Дамп объекта, сразу после создания

```Да ничего у него там - у него там нули - мы опять используем JOL для снятия дампа объекта```

> * вычислять сразу hashCode - дорого
> * hashCode может быть и переопределён
> * но место под system hashCode выделено у всех объектов - это не сложно проверить сделав дамп для любого другого класса

**```к чему тогда пустовать 4 байтам ??? а не приспособить ли VM их под что-то полезное ?```**

> :raised_hands: :raised_hands: зал - какое ещё есть собственное свойство, присущее любому объекту в java ?

# monitor

```методы wait/notify напоминают, что это конечно же монитор```

# Biased Locking

Не редко бывает так, что ```объект является thread-safe, но по факту он используется почти всегда одной нитью, и очень редко когда какая-то другая нить захватыает его монитор.```

особенно ```это харакетрно для наследия java 1.1 - vector, hashtable, properties, StringBuffer и других - у них все методы синхронизированы```

```Захват от отпускание монитора это не дешевые операции - поэтому изыскиваются возможности как облегчить```.
Что если сделать так - **```при захвате монитора помечать какой нитью она был захвачен - если той же - то можно избежать дорого захвата монитора. Эта привязка к нити и есть основная идея Biased locking```**.

```и именно маркер нити для biased locking и размещается в этих вакантных 4х байтах```.

_```Надо сказать, что biased locking куда обширней тема, но я рассмотрю её в связке с hashcode```_

# Biased Locking demo

```Если теперь захватим монитор объекта - то в заголовок объекта записывается id нити - id нити можно получить, например, используя thread dump, инструментами типа jvisualvm или через один com.sun MBean```

# StringBufferPerfTest

И чтобы показать эффект - давайте напилим такой вот бенчмарк - создаём пустую строку из StringBuffer - этот класс удобен для нас тем, что у него все методы synchronized - для бенчмарка только одна нить - в режиме biased locking и без него

# StringBufferPerfTest BiasedLockingStartupDelay

по-умолчанию есть задержка на включение BiasedLocking - её можно отключить этим вот флагом

# StringBufferPerfTest результаты

видно, что без него - захват монитора дороже

# identityHashCode

Так и что же происходит, когда надо записать hashCode ? **```Ведь есть место только для одного из них - либо hashcode, либо BiasedLocking```**

```Добавим ещё один StringBuffer, у которого в заголовке записан hashcode как у java.lang.Object```

# identityHashCode
добится этого можно используя ```System.identityHashCode - т.е смотрите - мы один раз - перед самим benchmark вызываем identityHashCode, и никаких изменений в теле самого benchmark```

# identityHashCode результаты

и как результат - ```объект с системным hashcode ведёт себя точно так же, как и в случае, когда biased locking отключён```.

# Revoke Biased Locking

```т.е system identityHashCode отзывает biased locking``` - И в таком случае захват монитора снова становится дорогим. у BiasedLocking ещё несколько краевых случаев, когда он может быть отозван.

_Вообще не стоит воспринимать BiasedLocking как панацею_ - ```это скорее такой способ как облегчить legacy код```, наследство из java 1.1 - на практике, как правило, редко приходится использовать и монитор объекта, и его системный hashcode, так, что ```отзыв BiasedLocking по причине identityHashCode случается на практике редко```

# Заключение

И в заключении:
> * Hash структуры данных это одни из быстрых структур данных,
> * Используя свои собственные ключи - не забывайте переоределять не только hashcode и equals, но и серьёзно рассматривайте возможность реализации интерфейс Comparable - это защитит вас в случае средне-плохого универсального способа вычисления hashcode - новой редакции Effective Java пока ещё нет, но я больше, чем уверен - это будет там.
> * Хотите, чтобы было ещё лучше и меньше коллизий - исследуйте свои hash-функции не только на предмет абсолютных коллизий, но и на предмет коллизий после мастшабирования на размеры массива - это может сократить расход памяти.
> * точно можно сказать - hashcode это не адрес объекта. По крайней мере, по-умолчанию.
> * жанглируя флагами vm из протёкшей абстракции Object.HashCode можно увидеть уши нескольких отличных инженерных решений в архитектуре - это и копирующий GC, и быстрые аллокации, и облегчённый завхат монитора, но не злоупотербляйте System.identityHashCode.
> * Meten is weten - выражение в голландском языке - буквально - измерение это знание - многие наивные рассуждения разбиваются в дребезги о реальность измерений

# Контакты

Все демо и слайды доступны на github-е.
Спасибо. :clap: :clap:
